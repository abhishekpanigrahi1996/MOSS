{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cow_OZ5Q9CEu",
        "outputId": "754974f9-55a8-4a60-a7f0-f983994ce86c"
      },
      "outputs": [],
      "source": [
        "!pip install typed-argument-parser\n",
        "!pip install stable-baselines3\n",
        "!pip install sb3_contrib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ek1-XXv9lm5"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import json\n",
        "import itertools\n",
        "from typing import Dict, Literal, Optional, List\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "from sb3_contrib import MaskablePPO\n",
        "from sb3_contrib.common.maskable.callbacks import MaskableEvalCallback\n",
        "from sb3_contrib.common.maskable.evaluation import evaluate_policy\n",
        "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
        "from stable_baselines3.common.env_util import SubprocVecEnv, make_vec_env, DummyVecEnv\n",
        "from stable_baselines3.common.callbacks import CheckpointCallback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EbtMQuEg9ECu"
      },
      "outputs": [],
      "source": [
        "# Configure model and training parameters.\n",
        "\n",
        "class Args(object):\n",
        "    no_wandb: bool = False\n",
        "    total_timesteps: int = 4_000_000\n",
        "    seed: int = random.randint(0, 2**32 - 1)\n",
        "    n_envs: int = 32\n",
        "    device: Literal['cpu', 'mps', 'cuda'] = 'cuda'\n",
        "    feature_extractor: Literal['none', 'tfh_small', 'tfh_big', 'tf', 'tfh_fast'] = 'tfh_fast'\n",
        "    env_num_inserts: int = 6\n",
        "    env_num_deletes: int = 6\n",
        "    env_max_tree_values: int = 24\n",
        "    env_max_values_per_node: int = 4\n",
        "    checkpoint_callback_freq: int = 50_000\n",
        "    s_net_arch: Dict[str, list[int]] = {'pi': [512, 512], 'vf': [512, 512]}\n",
        "    s_transformer_features_dim: int = 64\n",
        "    s_transformer_num_layers: int = 2\n",
        "    s_transformer_nhead: int = 2\n",
        "    s_n_epochs: int = 10\n",
        "    s_learning_rate: float = 1e-4\n",
        "    s_entropy_coef: int = 0\n",
        "    s_n_eval_episodes: int = 10_000\n",
        "    s_eval_freq: int = 50_000\n",
        "    s_n_seeds: int = 40\n",
        "    s_batch_size: int = 512\n",
        "    s_n_steps: int =  1000\n",
        "\n",
        "args = Args()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3gAXM5C49PBH"
      },
      "outputs": [],
      "source": [
        "# B+Tree adapted from https://gist.github.com/benben233/2c8a2a8ab44a7beabad0df1b6658232e\n",
        "# In the calculation functions, it contains the logic to compute the cost of an executed operation\n",
        "\n",
        "class Node(object):\n",
        "    \"\"\"Base node object. It should be an index node\n",
        "    Each node stores keys and children.\n",
        "\n",
        "    Attributes:\n",
        "        parent\n",
        "        cost_dict\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, cost_dict: dict, parent=None):\n",
        "        \"\"\"Child nodes are stored in values. Parent nodes simply act as a medium to traverse the tree.\n",
        "        :type parent: Node\"\"\"\n",
        "        self.keys: list = []\n",
        "        self.values: list[Node] = []\n",
        "        self.parent: Node = parent\n",
        "        self.cost_dict: dict = cost_dict\n",
        "\n",
        "    def index(self, key):\n",
        "        \"\"\"Return the index where the key should be.\n",
        "        :type key: str\n",
        "        \"\"\"\n",
        "        for i, item in enumerate(self.keys):\n",
        "            if key < item:\n",
        "                return i\n",
        "\n",
        "        return len(self.keys)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        return self.values[self.index(item)]\n",
        "\n",
        "    def __setitem__(self, key, value):\n",
        "        i = self.index(key)\n",
        "        self.keys[i:i] = [key]\n",
        "        self.values.pop(i)\n",
        "        self.values[i:i] = value\n",
        "\n",
        "    def split(self):\n",
        "        \"\"\"Splits the node into two and stores them as child nodes.\n",
        "        extract a pivot from the child to be inserted into the keys of the parent.\n",
        "        @:return key and two children\n",
        "        \"\"\"\n",
        "        self.cost_dict[\"splits\"] += 1\n",
        "        self.cost_dict[\"parent_splits\"] += 1\n",
        "\n",
        "        left = Node(cost_dict=self.cost_dict, parent=self.parent)\n",
        "\n",
        "        mid = len(self.keys) // 2\n",
        "\n",
        "        left.keys = self.keys[:mid]\n",
        "        left.values = self.values[: mid + 1]\n",
        "        for child in left.values:\n",
        "            child.parent = left\n",
        "\n",
        "        key = self.keys[mid]\n",
        "        self.keys = self.keys[mid + 1 :]\n",
        "        self.values = self.values[mid + 1 :]\n",
        "\n",
        "        return key, [left, self]\n",
        "\n",
        "    def __delitem__(self, key):\n",
        "        i = self.index(key)\n",
        "        del self.values[i]\n",
        "        if i < len(self.keys):\n",
        "            del self.keys[i]\n",
        "        else:\n",
        "            del self.keys[i - 1]\n",
        "\n",
        "    def fusion(self):\n",
        "        self.cost_dict[\"fusions\"] += 1\n",
        "        self.cost_dict[\"parent_fusions\"] += 1\n",
        "\n",
        "        index = self.parent.index(self.keys[0])\n",
        "        # merge this node with the next node\n",
        "        if index < len(self.parent.keys):\n",
        "            next_node: Node = self.parent.values[index + 1]\n",
        "            next_node.keys[0:0] = self.keys + [self.parent.keys[index]]\n",
        "            for child in self.values:\n",
        "                child.parent = next_node\n",
        "            next_node.values[0:0] = self.values\n",
        "        else:  # If self is the last node, merge with prev\n",
        "            prev: Node = self.parent.values[-2]\n",
        "            prev.keys += [self.parent.keys[-1]] + self.keys\n",
        "            for child in self.values:\n",
        "                child.parent = prev\n",
        "            prev.values += self.values\n",
        "\n",
        "    def borrow_key(self, minimum: int):\n",
        "        index = self.parent.index(self.keys[0])\n",
        "        if index < len(self.parent.keys):\n",
        "            next_node: Node = self.parent.values[index + 1]\n",
        "            if len(next_node.keys) > minimum:\n",
        "                self.keys += [self.parent.keys[index]]\n",
        "\n",
        "                borrow_node = next_node.values.pop(0)\n",
        "                borrow_node.parent = self\n",
        "                self.values += [borrow_node]\n",
        "                self.parent.keys[index] = next_node.keys.pop(0)\n",
        "                return True\n",
        "        elif index != 0:\n",
        "            prev: Node = self.parent.values[index - 1]\n",
        "            if len(prev.keys) > minimum:\n",
        "                self.keys[0:0] = [self.parent.keys[index - 1]]\n",
        "\n",
        "                borrow_node = prev.values.pop()\n",
        "                borrow_node.parent = self\n",
        "                self.values[0:0] = [borrow_node]\n",
        "                self.parent.keys[index - 1] = prev.keys.pop()\n",
        "                return True\n",
        "\n",
        "        return False\n",
        "\n",
        "\n",
        "class Leaf(Node):\n",
        "    def __init__(self, cost_dict: dict, parent=None, prev_node=None, next_node=None):\n",
        "        \"\"\"\n",
        "        Create a new leaf in the leaf link\n",
        "        :type prev_node: Leaf\n",
        "        :type next_node: Leaf\n",
        "        \"\"\"\n",
        "        super(Leaf, self).__init__(cost_dict, parent)\n",
        "        self.next: Leaf = next_node\n",
        "        if next_node is not None:\n",
        "            next_node.prev = self\n",
        "        self.prev: Leaf = prev_node\n",
        "        if prev_node is not None:\n",
        "            prev_node.next = self\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        return self.values[self.keys.index(item)]\n",
        "\n",
        "    def __setitem__(self, key, value):\n",
        "        i = self.index(key)\n",
        "        if key not in self.keys:\n",
        "            self.keys[i:i] = [key]\n",
        "            self.values[i:i] = [value]\n",
        "        else:\n",
        "            self.values[i - 1] = value\n",
        "\n",
        "    def split(self):\n",
        "        self.cost_dict[\"splits\"] += 1\n",
        "\n",
        "        left = Leaf(\n",
        "            cost_dict=self.cost_dict,\n",
        "            parent=self.parent,\n",
        "            prev_node=self.prev,\n",
        "            next_node=self,\n",
        "        )\n",
        "        mid = len(self.keys) // 2\n",
        "\n",
        "        left.keys = self.keys[:mid]\n",
        "        left.values = self.values[:mid]\n",
        "\n",
        "        self.keys: list = self.keys[mid:]\n",
        "        self.values: list = self.values[mid:]\n",
        "\n",
        "        # When the leaf node is split, set the parent key to the left-most key of the right child node.\n",
        "        return self.keys[0], [left, self]\n",
        "\n",
        "    def __delitem__(self, key):\n",
        "        i = self.keys.index(key)\n",
        "        del self.keys[i]\n",
        "        del self.values[i]\n",
        "\n",
        "    def fusion(self):\n",
        "        self.cost_dict[\"fusions\"] += 1\n",
        "\n",
        "        if self.next is not None and self.next.parent == self.parent:\n",
        "            self.next.keys[0:0] = self.keys\n",
        "            self.next.values[0:0] = self.values\n",
        "        else:\n",
        "            self.prev.keys += self.keys\n",
        "            self.prev.values += self.values\n",
        "\n",
        "        if self.next is not None:\n",
        "            self.next.prev = self.prev\n",
        "        if self.prev is not None:\n",
        "            self.prev.next = self.next\n",
        "\n",
        "    def borrow_key(self, minimum: int):\n",
        "        index = self.parent.index(self.keys[0])\n",
        "        if index < len(self.parent.keys) and len(self.next.keys) > minimum:\n",
        "            self.keys += [self.next.keys.pop(0)]\n",
        "            self.values += [self.next.values.pop(0)]\n",
        "            self.parent.keys[index] = self.next.keys[0]\n",
        "            return True\n",
        "        elif index != 0 and len(self.prev.keys) > minimum:\n",
        "            self.keys[0:0] = [self.prev.keys.pop()]\n",
        "            self.values[0:0] = [self.prev.values.pop()]\n",
        "            self.parent.keys[index - 1] = self.keys[0]\n",
        "            return True\n",
        "\n",
        "        return False\n",
        "\n",
        "\n",
        "class BPlusTree(object):\n",
        "    \"\"\"B+ tree object, consisting of nodes.\n",
        "\n",
        "    Nodes will automatically be split into two once it is full. When a split occurs, a key will\n",
        "    'float' upwards and be inserted into the parent node to act as a pivot.\n",
        "\n",
        "    Attributes:\n",
        "        maximum (int): The maximum number of keys each node can hold.\n",
        "    \"\"\"\n",
        "\n",
        "    root: Node\n",
        "    cost_dict: dict\n",
        "\n",
        "    def __init__(self, maximum=4):\n",
        "        self.cost_dict = {\n",
        "            \"splits\": 0,\n",
        "            \"parent_splits\": 0,\n",
        "            \"fusions\": 0,\n",
        "            \"parent_fusions\": 0,\n",
        "        }\n",
        "        self.root = Leaf(cost_dict=self.cost_dict)\n",
        "        self.maximum: int = maximum if maximum > 2 else 2\n",
        "        self.minimum: int = self.maximum // 2\n",
        "        self.depth = 0\n",
        "\n",
        "    def find(self, key) -> Leaf:\n",
        "        \"\"\"find the leaf\n",
        "\n",
        "        Returns:\n",
        "            Leaf: the leaf which should have the key\n",
        "        \"\"\"\n",
        "        node = self.root\n",
        "        # Traverse tree until leaf node is reached.\n",
        "        while type(node) is not Leaf:\n",
        "            node = node[key]\n",
        "\n",
        "        return node\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        return self.find(item)[item]\n",
        "\n",
        "    def query(self, key):\n",
        "        \"\"\"Returns a value for a given key, and None if the key does not exist.\"\"\"\n",
        "        leaf = self.find(key)\n",
        "        return leaf[key] if key in leaf.keys else None\n",
        "\n",
        "    def change(self, key, value):\n",
        "        \"\"\"change the value\n",
        "\n",
        "        Returns:\n",
        "            (bool,Leaf): the leaf where the key is. return False if the key does not exist\n",
        "        \"\"\"\n",
        "        leaf = self.find(key)\n",
        "        if key not in leaf.keys:\n",
        "            return False, leaf\n",
        "        else:\n",
        "            leaf[key] = value\n",
        "            return True, leaf\n",
        "\n",
        "    def __setitem__(self, key, value, leaf=None):\n",
        "        \"\"\"Inserts a key-value pair after traversing to a leaf node. If the leaf node is full, split\n",
        "        the leaf node into two.\n",
        "        \"\"\"\n",
        "        if leaf is None:\n",
        "            leaf = self.find(key)\n",
        "        leaf[key] = value\n",
        "        if len(leaf.keys) > self.maximum:\n",
        "            self.insert_index(*leaf.split())\n",
        "\n",
        "    def insert(self, key, value):\n",
        "        \"\"\"\n",
        "        Returns:\n",
        "            (bool,Leaf): the leaf where the key is inserted. return False if already has same key\n",
        "        \"\"\"\n",
        "        leaf = self.find(key)\n",
        "        if key in leaf.keys:\n",
        "            return False, leaf\n",
        "        else:\n",
        "            self.__setitem__(key, value, leaf)\n",
        "            return True, leaf\n",
        "\n",
        "    def insert_index(self, key, values: list[Node]):\n",
        "        \"\"\"For a parent and child node,\n",
        "        Insert the values from the child into the values of the parent.\"\"\"\n",
        "        parent = values[1].parent\n",
        "        if parent is None:\n",
        "            values[0].parent = values[1].parent = self.root = Node(\n",
        "                cost_dict=self.cost_dict\n",
        "            )\n",
        "            self.depth += 1\n",
        "            self.root.keys = [key]\n",
        "            self.root.values = values\n",
        "            return\n",
        "\n",
        "        parent[key] = values\n",
        "        # If the node is full, split the  node into two.\n",
        "        if len(parent.keys) > self.maximum:\n",
        "            self.insert_index(*parent.split())\n",
        "        # Once a leaf node is split, it consists of a internal node and two leaf nodes.\n",
        "        # These need to be re-inserted back into the tree.\n",
        "\n",
        "    def delete(self, key, node: Node = None):\n",
        "        if node is None:\n",
        "            node = self.find(key)\n",
        "        del node[key]\n",
        "\n",
        "        if len(node.keys) < self.minimum:\n",
        "            if node == self.root:\n",
        "                if len(self.root.keys) == 0 and len(self.root.values) > 0:\n",
        "                    self.root = self.root.values[0]\n",
        "                    self.root.parent = None\n",
        "                    self.depth -= 1\n",
        "                return\n",
        "\n",
        "            elif not node.borrow_key(self.minimum):\n",
        "                node.fusion()\n",
        "                self.delete(key, node.parent)\n",
        "\n",
        "    def show(self, node=None, file=None, _prefix=\"\", _last=True):\n",
        "        \"\"\"Prints the keys at each level.\"\"\"\n",
        "        if node is None:\n",
        "            node = self.root\n",
        "        print(_prefix, \"`- \" if _last else \"|- \", node.keys, sep=\"\", file=file)\n",
        "        _prefix += \"   \" if _last else \"|  \"\n",
        "\n",
        "        if type(node) is Node:\n",
        "            # Recursively print the key of child nodes (if these exist).\n",
        "            for i, child in enumerate(node.values):\n",
        "                _last = i == len(node.values) - 1\n",
        "                self.show(child, file, _prefix, _last)\n",
        "\n",
        "    def output(self):\n",
        "        return tuple(self.cost_dict.values()), self.depth\n",
        "\n",
        "    def readfile(self, reader):\n",
        "        i = 0\n",
        "        for i, line in enumerate(reader):\n",
        "            s = line.decode().split(maxsplit=1)\n",
        "            self[s[0]] = s[1]\n",
        "            if i % 1000 == 0:\n",
        "                print(\"Insert \" + str(i) + \"items\")\n",
        "        return i + 1\n",
        "\n",
        "    def leftmost_leaf(self) -> Leaf:\n",
        "        node = self.root\n",
        "        while type(node) is not Leaf:\n",
        "            node = node.values[0]\n",
        "        return node\n",
        "\n",
        "    def get_obs_space_representation(self, max_depth):\n",
        "        \"\"\"\n",
        "        Returns a 1D array representation of the tree:\n",
        "        - Keys in each node are padded with zeros to `maximum` keys.\n",
        "        - The entire structure is padded with zeros to account for the maximum possible nodes at each level.\n",
        "        \"\"\"\n",
        "\n",
        "        max_depth += 1 # Add 1 to account for the root node\n",
        "        levels = [[] for _ in range(max_depth)]\n",
        "\n",
        "        def dfs(node: Node, depth: int):\n",
        "            if depth == max_depth:\n",
        "                return\n",
        "\n",
        "            level = levels[depth]\n",
        "\n",
        "            if node is None:\n",
        "                level += [0] * self.maximum\n",
        "                children = []\n",
        "            else:\n",
        "                level += node.keys.copy() + [0] * (self.maximum - len(node.keys))\n",
        "                assert len(level) % self.maximum == 0\n",
        "\n",
        "                if type(node) is Leaf:\n",
        "                    children = []\n",
        "                else:\n",
        "                    children = node.values.copy()\n",
        "\n",
        "\n",
        "            while len(children) < self.maximum + 1:\n",
        "                children.append(None)\n",
        "\n",
        "            assert len(children) == self.maximum + 1\n",
        "\n",
        "            for child in children:\n",
        "                dfs(child, depth + 1)\n",
        "\n",
        "        # Start traversal from the root\n",
        "        dfs(self.root, 0)\n",
        "\n",
        "        # Make sure the layers are filled correctly\n",
        "        prev_nodes = 1\n",
        "        for level in levels[1:]:\n",
        "            cur_nodes = prev_nodes * (self.maximum + 1)\n",
        "            assert len(level) == cur_nodes * self.maximum\n",
        "            prev_nodes = cur_nodes\n",
        "\n",
        "        flattened_representation = list(itertools.chain(*levels))\n",
        "        return np.array(flattened_representation).flatten()\n",
        "\n",
        "    def get_obs_space_feature_representation(self, max_depth):\n",
        "        \"\"\"\n",
        "        Returns a 1D array representation of the tree with feature engineering:\n",
        "        - Each node is represented by its minimum key, maximum key, and fill percentage.\n",
        "        - The structure is padded with zeros to account for the maximum possible nodes at each level.\n",
        "        \"\"\"\n",
        "\n",
        "        max_depth += 1  # Add 1 to account for the root node\n",
        "        levels = [[] for _ in range(max_depth)]\n",
        "\n",
        "        def dfs(node: Node, depth: int):\n",
        "            if depth == max_depth:\n",
        "                return\n",
        "\n",
        "            level = levels[depth]\n",
        "\n",
        "            if node is None:\n",
        "                level += [0, 0, 0]\n",
        "                children = []\n",
        "            else:\n",
        "                min_key = min(node.keys) if node.keys else 0\n",
        "                max_key = max(node.keys) if node.keys else 0\n",
        "                fill_percentage = len(node.keys) / self.maximum\n",
        "\n",
        "                level += [min_key, max_key, fill_percentage]\n",
        "\n",
        "                if isinstance(node, Leaf):\n",
        "                    children = []\n",
        "                else:\n",
        "                    children = node.values.copy()\n",
        "\n",
        "            while len(children) < self.maximum + 1:\n",
        "                children.append(None)\n",
        "\n",
        "            assert len(children) == self.maximum + 1\n",
        "\n",
        "            for child in children:\n",
        "                dfs(child, depth + 1)\n",
        "\n",
        "        dfs(self.root, 0)\n",
        "\n",
        "        # Make sure the layers are filled correctly\n",
        "        prev_nodes = 1\n",
        "        for level in levels[1:]:\n",
        "            cur_nodes = prev_nodes * (self.maximum + 1)\n",
        "            assert len(level) == cur_nodes * 3  # **3 features per node (min, max, fill percentage).**\n",
        "            prev_nodes = cur_nodes\n",
        "\n",
        "        flattened_representation = list(itertools.chain(*levels))\n",
        "        return np.array(flattened_representation).flatten()\n",
        "\n",
        "\n",
        "    def reset_cost_dict(self):\n",
        "        for key in self.cost_dict.keys():\n",
        "            self.cost_dict[key] = 0\n",
        "\n",
        "    def calculate_reward(self):\n",
        "        cost_factors = {\n",
        "            \"splits\": 2,\n",
        "            \"parent_splits\": 1,\n",
        "            \"fusions\": 2,\n",
        "            \"parent_fusions\": 1,\n",
        "        }\n",
        "        reward = 0\n",
        "        for key in self.cost_dict.keys():\n",
        "            reward += cost_factors[key] * self.cost_dict[key]\n",
        "        self.reset_cost_dict()\n",
        "        return reward\n",
        "\n",
        "\n",
        "\n",
        "def calculate_length_max_depth_of_tree(max_tree_values, max_keys):\n",
        "    \"\"\"\n",
        "    Calculate the length of the observation space representation.\n",
        "    \"\"\"\n",
        "    # max_depth = calculate_max_depth(num_inserts,num_values,max_keys)\n",
        "\n",
        "    max_depth = 1 + np.log(max_tree_values) / (np.log(max_keys + 1))\n",
        "    max_depth = int(max_depth)\n",
        "    #print(\"Max Depth:\", max_depth)\n",
        "\n",
        "    total_keys = 3\n",
        "    prev_nodes = 1\n",
        "    for level in range(1, max_depth+1):\n",
        "        cur_nodes = prev_nodes * (max_keys + 1)\n",
        "        total_keys += cur_nodes * 3\n",
        "\n",
        "        values_in_level = cur_nodes * 3\n",
        "        prev_nodes = cur_nodes\n",
        "    #print(\"Total Keys:\", total_keys)\n",
        "    #print(\"Values in Level:\", values_in_level)\n",
        "    return  total_keys, max_depth\n",
        "\n",
        "\n",
        "def printTree(tree):\n",
        "    current_node = tree.root\n",
        "    if current_node is not None:\n",
        "        print(current_node.values)\n",
        "        print(current_node.keys)\n",
        "        print(current_node.nextKey)\n",
        "        print(current_node.parent)\n",
        "        print(current_node.check_leaf)\n",
        "        print(\"\\n\")\n",
        "        if not current_node.check_leaf:\n",
        "            for i, item in enumerate(current_node.keys):\n",
        "                printTree(current_node.keys[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I1h1kCPA9WJs"
      },
      "outputs": [],
      "source": [
        "# The training environment which uses the previously defined B-tree\n",
        "# The important pieces are contained in the step function.\n",
        "\n",
        "class BScheduler(gym.Env):\n",
        "    def __init__(self, args: Args = Args(), render_mode: Optional[str] = None):\n",
        "        self.num_inserts = args.env_num_inserts\n",
        "        self.num_deletes =  args.env_num_deletes\n",
        "        self.num_operations = self.num_inserts + self.num_deletes\n",
        "        self.max_tree_values = args.env_max_tree_values\n",
        "        self.max_values_per_node = args.env_max_values_per_node\n",
        "        self.action_space = spaces.Discrete(self.num_operations)\n",
        "        self.low = -2\n",
        "        self.high = self.max_tree_values + self.num_operations\n",
        "        self.len_tree_obs_space, self.max_possible_tree_depth = calculate_length_max_depth_of_tree(\n",
        "            self.max_tree_values, self.max_values_per_node\n",
        "        )\n",
        "        self.observation_space = spaces.Box(\n",
        "            low=self.low,\n",
        "            high=self.high,\n",
        "            shape=(self.len_tree_obs_space + self.num_operations,),\n",
        "            dtype=np.float32,\n",
        "        )\n",
        "        self.tree = None\n",
        "        self.tree_representation = None\n",
        "        self.inserts = None\n",
        "        self.deletes = None\n",
        "        self.rng = np.random.default_rng(None)\n",
        "\n",
        "\n",
        "    def _get_obs(self):\n",
        "        self.tree_representation = self.tree.get_obs_space_feature_representation(\n",
        "            self.max_possible_tree_depth\n",
        "        )\n",
        "        assert len(self.tree_representation) == self.len_tree_obs_space\n",
        "        assert self.tree_representation[-1] == 0\n",
        "        return np.concatenate([self.operations, self.tree_representation], dtype=np.float32)\n",
        "\n",
        "    def reset(self, seed: Optional[int] = None, options: Optional[dict] = None):\n",
        "        super().reset(seed=seed)\n",
        "        if seed is not None:\n",
        "            self.rng = np.random.default_rng(seed=seed)\n",
        "        self.tree = BPlusTree(maximum=self.max_values_per_node)\n",
        "        self.tree_numbers = self.rng.choice(\n",
        "            a=np.arange(1, self.high), size=self.max_tree_values + self.num_inserts, replace=False\n",
        "        )\n",
        "        inserts = self.tree_numbers[self.max_tree_values:]\n",
        "        for i in range(self.max_tree_values - self.num_inserts):\n",
        "            self.tree.insert(self.tree_numbers[i], self.tree_numbers[i])\n",
        "\n",
        "        deletes = self.rng.choice(\n",
        "            self.tree_numbers[:self.num_deletes], self.num_deletes, replace=False\n",
        "        )\n",
        "\n",
        "        sorted_deletes = np.sort(deletes)\n",
        "        sorted_inserts = np.sort(inserts)\n",
        "        self.tree.calculate_reward()  # to reset counters\n",
        "        self.operations = np.concatenate([sorted_inserts, sorted_deletes])\n",
        "        return self._get_obs(), {}\n",
        "\n",
        "    def step(self, action):\n",
        "        info = {}\n",
        "        truncated = False\n",
        "        terminated = False\n",
        "        reward = 0\n",
        "        # Check for valid action choices\n",
        "        operation = self.operations[action]\n",
        "        if operation == -1:\n",
        "            print(\"operation\", operation)\n",
        "            print(\"operations\", self.operations)\n",
        "            raise \"This should not happen if you use MaskablePPO\"\n",
        "\n",
        "        # If an action is contained in the first half of the actions, it is an insert operation\n",
        "        elif action < self.num_operations // 2:\n",
        "            self.tree.insert(operation, operation)\n",
        "        else:\n",
        "            self.tree.delete(operation)\n",
        "        self.operations[action] = -1\n",
        "\n",
        "        # Once the todo-list is empty, the process finishes\n",
        "        if (self.operations == -1).all():\n",
        "            terminated = True\n",
        "\n",
        "        observation = self._get_obs()\n",
        "\n",
        "        # The tree library contains the logic to compute the cost of the last executed operation\n",
        "        reward = -1 * self.tree.calculate_reward()\n",
        "        return observation, reward, terminated, truncated, info\n",
        "\n",
        "    def action_masks(self) -> List[bool]:\n",
        "        ret = self.operations != -1\n",
        "        return ret\n",
        "\n",
        "\n",
        "gym.register(\n",
        "    id=\"BScheduler-v0\",\n",
        "    entry_point=BScheduler,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Gp85mY_9JBP"
      },
      "outputs": [],
      "source": [
        "class OptimizedHierarchicalBPlusFeatureExtractor(BaseFeaturesExtractor):\n",
        "    \"\"\"\n",
        "    The feature extractor, which contains the main logic of the hierarchical model described in the text.\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 observation_space: gym.spaces.Box,\n",
        "                 feature_dim: int = 256,\n",
        "                 values_per_node: int = 4,\n",
        "                 num_ops: int = 6,\n",
        "                 num_heads: int = 4,\n",
        "                 dropout: float = 0.1,\n",
        "                 max_levels: int = 10):\n",
        "        super(OptimizedHierarchicalBPlusFeatureExtractor, self).__init__(\n",
        "            observation_space,\n",
        "            feature_dim + num_ops\n",
        "        )\n",
        "        self.features_per_node = 3\n",
        "        self.values_per_node = values_per_node\n",
        "        self.children_per_node = values_per_node + 1\n",
        "        self.num_ops = num_ops\n",
        "        self.feature_dim = feature_dim\n",
        "        self.max_levels = max_levels\n",
        "        self.debug = False\n",
        "\n",
        "        self.level_structure = self._compute_level_structure(observation_space.shape)\n",
        "\n",
        "        # By default, a TransformerEncoderLayer is used for the computation. It is shared among all levels of the tree.\n",
        "        self.transformer = nn.TransformerEncoderLayer(\n",
        "            d_model=feature_dim,\n",
        "            nhead=num_heads,\n",
        "            dim_feedforward=feature_dim,\n",
        "            dropout=dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.linear = nn.Linear(feature_dim, feature_dim)\n",
        "        self.leaf_embedding = nn.Linear(self.features_per_node, feature_dim)\n",
        "        self.node_combiner = nn.Linear(feature_dim * self.children_per_node + self.features_per_node, feature_dim)\n",
        "        self.level_embeddings = nn.Parameter(torch.randn(max_levels, 1, feature_dim))\n",
        "        self.level_norm = nn.LayerNorm(feature_dim)\n",
        "        self.node_norm = nn.LayerNorm(feature_dim * self.children_per_node + self.features_per_node)\n",
        "\n",
        "    def _compute_level_structure(self, obs):\n",
        "        \"\"\"\n",
        "        Pre-compute the structure of each level in the tree.\n",
        "        Calculate leaf start index and propagate upwards to get all index ranges for all nodes.\n",
        "        \"\"\"\n",
        "        num_levels = 0\n",
        "        idx = 1\n",
        "        obs_without_actions = obs[0] - self.num_ops\n",
        "        # Determine the number of levels and leaf start index\n",
        "        while idx < obs_without_actions:\n",
        "            if idx * self.children_per_node > obs_without_actions:\n",
        "                break\n",
        "            idx *= self.children_per_node\n",
        "            num_levels += 1\n",
        "\n",
        "        level_structure = []\n",
        "        current_value_end = obs_without_actions\n",
        "\n",
        "        for level in range(num_levels, -1, -1):\n",
        "            nodes_this_level = idx if level == num_levels else idx // (self.children_per_node ** (num_levels - level))\n",
        "            parent_nodes = nodes_this_level // self.children_per_node\n",
        "\n",
        "            value_start_idx = current_value_end - nodes_this_level * self.features_per_node\n",
        "\n",
        "            level_info = {\n",
        "                'num_nodes': nodes_this_level,\n",
        "                'num_parents': parent_nodes,\n",
        "                'value_start_idx': value_start_idx,\n",
        "                'values_per_level': nodes_this_level * self.features_per_node,\n",
        "                'value_end_idx': current_value_end\n",
        "            }\n",
        "\n",
        "            level_structure.append(level_info)\n",
        "            current_value_end = value_start_idx\n",
        "\n",
        "        return level_structure\n",
        "\n",
        "\n",
        "    def _get_empty_mask(self, node_values):\n",
        "        empty = node_values[..., 0] == 0\n",
        "        return empty\n",
        "\n",
        "    def process_level(self, level_info, current_embeddings, tree_data, level_idx):\n",
        "        # Parse one level of the tree using the data stored in tree_data\n",
        "        batch_size = current_embeddings.shape[0]\n",
        "        num_parents = level_info['num_parents']\n",
        "\n",
        "        if num_parents == 0:  # root node have to pass\n",
        "            return current_embeddings\n",
        "\n",
        "\n",
        "        parent_values_start = level_info['value_start_idx']\n",
        "        parent_values = tree_data[:, parent_values_start - num_parents * self.features_per_node:parent_values_start]\n",
        "        parent_values = parent_values.view(batch_size, num_parents, self.features_per_node)\n",
        "        empty_mask = self._get_empty_mask(parent_values)\n",
        "\n",
        "        output_embeddings = torch.zeros(\n",
        "            batch_size, num_parents, self.feature_dim,\n",
        "            device=current_embeddings.device\n",
        "        )\n",
        "\n",
        "        if (~empty_mask).any():\n",
        "            non_empty_indices = torch.nonzero(~empty_mask)\n",
        "            non_empty_parents = parent_values[~empty_mask]\n",
        "\n",
        "\n",
        "            grouped_children = current_embeddings.view(batch_size, -1, self.children_per_node, self.feature_dim)\n",
        "            non_empty_children = grouped_children[non_empty_indices[:, 0], non_empty_indices[:, 1]]\n",
        "\n",
        "            children_flat = non_empty_children.view(-1, self.children_per_node * self.feature_dim)\n",
        "\n",
        "            combined = torch.cat([children_flat, non_empty_parents], dim=1)\n",
        "            #combined = self.node_norm(combined)\n",
        "            parent_embeddings = self.node_combiner(combined)\n",
        "\n",
        "            level_embedding = self.level_embeddings[level_idx].expand(len(parent_embeddings), -1)\n",
        "            parent_embeddings = parent_embeddings + level_embedding\n",
        "            parent_embeddings = self.level_norm(parent_embeddings)\n",
        "\n",
        "            transformed = self.transformer(parent_embeddings.unsqueeze(1)).squeeze(1)\n",
        "            #transformed = self.linear(parent_embeddings.unsqueeze(1)).squeeze(1) # linear version\n",
        "            output_embeddings[non_empty_indices[:, 0], non_empty_indices[:, 1]] = transformed\n",
        "\n",
        "        return output_embeddings\n",
        "\n",
        "    def forward(self, obs: torch.Tensor) -> torch.Tensor:\n",
        "\n",
        "        batch_size = obs.shape[0]\n",
        "        ops = obs[:, :self.num_ops]\n",
        "        tree_data = obs[:, self.num_ops:]\n",
        "        tree_data = (tree_data - tree_data.min(dim=1, keepdim=True).values) / (tree_data.max(dim=1, keepdim=True).values - tree_data.min(dim=1, keepdim=True).values + 1e-8)\n",
        "\n",
        "        # Process leaf nodes separately\n",
        "        num_leaf_nodes = self.level_structure[0]['num_nodes'] if self.level_structure else (tree_data.shape[1] // self.features_per_node)\n",
        "        leaf_values = tree_data[:, -num_leaf_nodes * self.features_per_node:].view(\n",
        "            batch_size, num_leaf_nodes, self.features_per_node\n",
        "        )\n",
        "\n",
        "        leaf_embeddings = torch.zeros(batch_size, num_leaf_nodes, self.feature_dim, device=obs.device)\n",
        "\n",
        "        empty_mask = self._get_empty_mask(leaf_values)\n",
        "        if (~empty_mask).any():\n",
        "            non_empty_leaves = leaf_values[~empty_mask]\n",
        "            non_empty_indices = torch.nonzero(~empty_mask)\n",
        "\n",
        "            embeddings = self.leaf_embedding(non_empty_leaves)\n",
        "\n",
        "            level_embedding = self.level_embeddings[0].expand(len(embeddings), -1)\n",
        "            embeddings = embeddings + level_embedding\n",
        "            embeddings = self.level_norm(embeddings)\n",
        "\n",
        "            leaf_embeddings[non_empty_indices[:, 0], non_empty_indices[:, 1]] = embeddings\n",
        "\n",
        "        current_embeddings = leaf_embeddings\n",
        "\n",
        "        for level_idx, level_info in enumerate(self.level_structure):\n",
        "            current_embeddings = self.process_level(\n",
        "                level_info,\n",
        "                current_embeddings,\n",
        "                tree_data,\n",
        "                level_idx\n",
        "            )\n",
        "\n",
        "        root_embedding = current_embeddings.squeeze(1)\n",
        "        return torch.cat([root_embedding, ops], dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vH4YkQjJ-w54"
      },
      "outputs": [],
      "source": [
        "# A few helper functions for initialization\n",
        "def get_env(args: Args):\n",
        "    env = get_env_func(args)()\n",
        "    env.reset(seed=args.seed)\n",
        "    return env\n",
        "\n",
        "\n",
        "def get_env_func(args: Args):\n",
        "    def env_func():\n",
        "        env = gym.make(\"BScheduler-v0\", args=args, render_mode=None)\n",
        "        return env\n",
        "\n",
        "    return env_func\n",
        "\n",
        "\n",
        "def get_vec_env(args: Args, n_envs_override: int = None):\n",
        "    n_envs = n_envs_override or args.n_envs\n",
        "    env_func = get_env_func(args)\n",
        "    env = make_vec_env(env_func, n_envs=n_envs, vec_env_cls=DummyVecEnv)\n",
        "    return env\n",
        "\n",
        "\n",
        "def create_model(args: Args, env: BScheduler, eval_env: BScheduler):\n",
        "    print(f\"Creating model with args: {args}\")\n",
        "    random.seed(args.seed)\n",
        "    np.random.seed(args.seed)\n",
        "\n",
        "    policy_kwargs = dict(\n",
        "        net_arch=args.s_net_arch,\n",
        "    )\n",
        "\n",
        "    if args.feature_extractor == \"tfh_fast\":  # Fast Hierarchical Transformer Feature Extractor\n",
        "        policy_kwargs['features_extractor_class'] = OptimizedHierarchicalBPlusFeatureExtractor\n",
        "        policy_kwargs['features_extractor_kwargs'] = dict(\n",
        "            feature_dim=args.s_transformer_features_dim,\n",
        "            values_per_node=args.env_max_values_per_node,\n",
        "            num_ops=args.env_num_inserts + args.env_num_deletes,\n",
        "            num_heads=args.s_transformer_nhead,\n",
        "            dropout=0.1,\n",
        "            max_levels=5,\n",
        "        )\n",
        "\n",
        "    elif args.feature_extractor == 'none':\n",
        "        print(\"Training without special feature extractor\")\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown feature_extractor: {args.feature_extractor}\")\n",
        "\n",
        "    model = MaskablePPO(\n",
        "        \"MlpPolicy\",\n",
        "        env,\n",
        "        n_epochs=args.s_n_epochs,\n",
        "        learning_rate=args.s_learning_rate,\n",
        "        verbose=1,\n",
        "        gamma=0.999,\n",
        "        device=args.device,\n",
        "        policy_kwargs=policy_kwargs,\n",
        "        seed=args.seed,\n",
        "        batch_size=args.s_batch_size,\n",
        "    )\n",
        "\n",
        "    print(\"Model policy:\", model.policy)\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WUaSuFz2-y6f",
        "outputId": "001e6531-94c8-48ea-83b3-f48b432ebda6"
      },
      "outputs": [],
      "source": [
        "# Create the environment\n",
        "vec_env = get_vec_env(args)\n",
        "eval_env = get_vec_env(args, 1)\n",
        "\n",
        "# Initialize the model\n",
        "model = create_model(args, vec_env, eval_env)\n",
        "\n",
        "# Start the training process\n",
        "model.learn(total_timesteps=args.total_timesteps)\n",
        "\n",
        "# Compute the mean reward of the model for the evaluation, which can be compared to the table in the text.\n",
        "eval = evaluate_policy(model, vec_env, n_eval_episodes=1000, warn=False)\n",
        "print(\"Evaluation (mean/std):\", eval)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
