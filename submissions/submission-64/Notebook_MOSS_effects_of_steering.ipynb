{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "Mr8xGQ3VPZGk",
   "metadata": {
    "id": "Mr8xGQ3VPZGk"
   },
   "source": [
    "# **The Necessity for Intervention Fidelity: Unintended Side Effects When Steering LLMs**\n",
    "\n",
    "*Authors: Jonas B. Raedler, Weiyue Li, Manasvi Goyal, Alyssa Mia Taliotis, Siddharth Swaroop, Weiwei Pan*\n",
    "\n",
    "---\n",
    "This is the notebook that accompanies our paper, published at the *Methods and Opportunities at Small Scale (MOSS)* workshop, held at ICML 2025 (Vancouver, Canada)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-lrIJ_K5HPsq",
   "metadata": {
    "id": "-lrIJ_K5HPsq"
   },
   "source": [
    "### **Please Read:**\n",
    "\n",
    "**Instructions**\n",
    "1. This notebook makes use of the `transformer_lens` library. The pretrained models that it uses require a lot of memory, so you'll have to change the runtime environment of this notebook: **Change the runtime type from CPU to v2-8 TPU**. This is available in Google Colab free tier (I've tested it successfully --- there might be usage limits after using it for a while, but it should be usable again after a while).\n",
    "\n",
    "2. Furthermore, Google Colab doesn't seem to have the `transformer_lens` library pre-installed. Try to execute the imports cell - if it fails, **uncomment the `!pip install` command, install the package, and then rerun the imports**.\n",
    "\n",
    "3. This notebook uses the `google/gemma-2-2b` family of models. Using them requires a huggingface token (which is free). You can get one here: https://huggingface.co/docs/hub/en/security-tokens. Provide your access token in the field `HUGGINGFACE_TOKEN` below.\n",
    "\n",
    "4. Last but not least, this notebook uses the StereoSet dataset. You can get the data from here: https://github.com/moinnadeem/StereoSet/blob/master/data/dev.json. Download the dev.json file and upload it to this session (on the left under \"Files\", select \"Upload to session storage\").\n",
    "\n",
    "\n",
    "**Further Information**\n",
    "\n",
    "In the interest of time, this notebook does not run our experiments on the entire dataset (this would take significantly longer than only 3 hours). Instead, we run our experiments on a subset of the data. From the four available bias types, we chose two: \"gender\" and \"race\". We also run our experiments on only one dataset (intersentence), use only 30 samples per bias type, and steer at 3 layers (5, 11, 17) instead of every second layer.\n",
    "These decisions were made to make it possible to run this notebook in 1.5 hours, while still covering the entire experiment spectrum as holistically as possible.\n",
    "\n",
    "We aimed for a time of 1.5 hours, as one run of this notebook only executes the experiments for either the base or the fine-tuned model. If desired, the reviewer can change the model and rerun the notebook to get the other set of results.\n",
    "\n",
    "All our decisions can be altered, if desired, though we recommend to keep a wide range of layers (i.e., don't pick 1, 2, 3). We specify these decision in the first cell and they can be altered there.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5f7995-6d73-4111-9dd8-eb19ba3e72b9",
   "metadata": {
    "id": "4d5f7995-6d73-4111-9dd8-eb19ba3e72b9"
   },
   "source": [
    "**1. Import Libraries**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Aq5BEKAnNXc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### MODEL TRAIN STATE\n",
    "# TRAIN_STATE = \"base\"    # uncomment depending on which model you want to run\n",
    "TRAIN_STATE = \"instruct\"\n",
    "\n",
    "\n",
    "#### DATASET SPECIFICATION\n",
    "# mode = \"intra\"\n",
    "mode = \"inter\"    # uncomment depending on which dataset you want to run\n",
    "\n",
    "\n",
    "#### HYPERPARAMETERS\n",
    "all_layer_ids = [5, 11, 17]\n",
    "N_SAMPLES = 30\n",
    "\n",
    "\n",
    "#### BIAS TYPES\n",
    "stereo_bias_types = [\"gender\", \"race\"]  # [\"gender\", \"profession\", \"race\", \"religion\"]  -- for time's sake, we will only consider 2 bias types\n",
    "\n",
    "\n",
    "#### HUGGINGFACE TOKEN\n",
    "HUGGINGFACE_TOKEN = \"your token here\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Jv4fRBobJY8p",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install if necessary!\n",
    "#!pip install transformer_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3268fb-b8b9-4cce-b050-7a696679523c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from transformer_lens import HookedTransformer\n",
    "from tqdm import tqdm\n",
    "from huggingface_hub import login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6twYsOMGJ8Jv",
   "metadata": {},
   "outputs": [],
   "source": [
    "login(token=HUGGINGFACE_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5016b458-e233-48e3-a650-f6ae2877cd30",
   "metadata": {
    "id": "5016b458-e233-48e3-a650-f6ae2877cd30"
   },
   "source": [
    "**2. Get the StereoSet Data**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42735fb7-f64a-4575-88bf-42dd2d4b07f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"dev.json\"\n",
    "with open(DATA_PATH) as dev_file:\n",
    "    dev = json.load(dev_file)\n",
    "\n",
    "inter = dev[\"data\"][\"intersentence\"]\n",
    "intra = dev[\"data\"][\"intrasentence\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d52492-0488-44d4-a33a-4fc27c3eafa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the relevant data from the dev.json stereoset file\n",
    "def get_metadata(result_dict, row_idx, metadata, mode):\n",
    "\n",
    "    row_metadata = metadata[row_idx]\n",
    "\n",
    "    # Basic Information\n",
    "    result_dict[\"bias_type\"].append(row_metadata[\"bias_type\"])\n",
    "    result_dict[\"context\"].append(row_metadata[\"context\"])\n",
    "\n",
    "    result_dict[\"ans0\"].append(row_metadata[\"sentences\"][0][\"sentence\"])\n",
    "    result_dict[\"ans1\"].append(row_metadata[\"sentences\"][1][\"sentence\"])\n",
    "    result_dict[\"ans2\"].append(row_metadata[\"sentences\"][2][\"sentence\"])\n",
    "\n",
    "    result_dict[\"ans0_answer_type\"].append(row_metadata[\"sentences\"][0][\"gold_label\"])\n",
    "    result_dict[\"ans1_answer_type\"].append(row_metadata[\"sentences\"][1][\"gold_label\"])\n",
    "    result_dict[\"ans2_answer_type\"].append(row_metadata[\"sentences\"][2][\"gold_label\"])\n",
    "\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2abf77-e2d7-4549-9ca6-f1df933f73ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put the stereoset data into datafrmes\n",
    "intra_dict = {\n",
    "    \"bias_type\": [],\n",
    "    \"context\": [],\n",
    "    \"ans0\": [],\n",
    "    \"ans1\": [],\n",
    "    \"ans2\": [],\n",
    "    \"ans0_answer_type\": [],\n",
    "    \"ans1_answer_type\": [],\n",
    "    \"ans2_answer_type\": [],\n",
    "}\n",
    "\n",
    "inter_dict = copy.deepcopy(intra_dict)\n",
    "\n",
    "# Set up df for both intra- and intersentence data\n",
    "for row_idx in range(len(inter)):\n",
    "    inter_dict = get_metadata(inter_dict, row_idx, inter, mode=\"inter\")\n",
    "inter_df = pd.DataFrame.from_dict(inter_dict)\n",
    "\n",
    "for row_idx in range(len(intra)):\n",
    "    intra_dict = get_metadata(intra_dict, row_idx, intra, mode=\"intra\")\n",
    "intra_df = pd.DataFrame.from_dict(intra_dict)\n",
    "\n",
    "all_dfs = {\n",
    "    \"inter\": inter_df,\n",
    "    \"intra\": intra_df\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668f5eca-2d34-4963-9a3c-a661eab46dcb",
   "metadata": {
    "id": "668f5eca-2d34-4963-9a3c-a661eab46dcb"
   },
   "source": [
    "**3. Prepare Steering Functions**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e649ca-9f94-4f4f-9633-f2508df7502d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this gets the formatted context+question+answer for each entry in the dataset\n",
    "def get_prompt_and_answer_choices_stereoset(row, data_type):\n",
    "    choices = [\"A. \" + row[\"ans0\"], \"B. \" + row[\"ans1\"], \"C. \" + row[\"ans2\"]]\n",
    "    choices_dict = {k: v for k, v in [[choice[0], choice[3:]] for choice in choices]}\n",
    "\n",
    "    question = \"Choose the most appropriate sentence below:\"\n",
    "\n",
    "    context = row[\"context\"]\n",
    "    prompt = (\n",
    "        f\"{context}\\n\\n\"\n",
    "        f\"{question}\\n\"\n",
    "        f\"{choices[0]}\\n\"\n",
    "        f\"{choices[1]}\\n\"\n",
    "        f\"{choices[2]}\\n\\n\"\n",
    "        f\"Answer: \"\n",
    "    )\n",
    "\n",
    "    return prompt, choices, choices_dict\n",
    "\n",
    "\n",
    "# this determines which answer index corresponds to which answer type\n",
    "def get_answer_ids(row):\n",
    "    answers = {\n",
    "        row[\"ans0_answer_type\"]: 0,\n",
    "        row[\"ans1_answer_type\"]: 1,\n",
    "        row[\"ans2_answer_type\"]: 2\n",
    "    }\n",
    "    stereo_idx = answers[\"stereotype\"]\n",
    "    anti_stereo_idx = answers[\"anti-stereotype\"]\n",
    "    unrelated_idx = answers[\"unrelated\"]\n",
    "\n",
    "    return stereo_idx, anti_stereo_idx, unrelated_idx\n",
    "\n",
    "\n",
    "# this converts a prediction (index) into answer type\n",
    "def determine_answer_type_stereoset(row, pred_column):\n",
    "    model_pred = str(row[pred_column])\n",
    "    answer_type = row[f\"ans{model_pred}_answer_type\"]\n",
    "\n",
    "    answer_type_to_label = {\n",
    "        \"unrelated\": 0,\n",
    "        \"stereotype\": 1,\n",
    "        \"anti-stereotype\": 2\n",
    "    }\n",
    "\n",
    "    return answer_type_to_label[answer_type]\n",
    "\n",
    "\n",
    "# this defines the steering hook that is used for intervention\n",
    "def make_steering_hook(curr_steering_config):\n",
    "\n",
    "    def steering_hook(resid_pre, hook):\n",
    "        if resid_pre.shape[1]==1:\n",
    "            return\n",
    "\n",
    "        # Init from config\n",
    "        COEFF = curr_steering_config[\"COEFF\"]\n",
    "        steer_vector = curr_steering_config[\"steering_vector\"]\n",
    "\n",
    "        vecs = []\n",
    "        vecs.extend([steer_vector] * NUMBER_OF_MULTIPLE_CHOICES)\n",
    "        steer = torch.stack(vecs, dim=0).to(resid_pre.device) * COEFF\n",
    "\n",
    "        # steer is [batch, d_model], so unsqueeze to [batch,1,d_model]\n",
    "        resid_pre += steer.unsqueeze(1)\n",
    "\n",
    "    return steering_hook\n",
    "\n",
    "\n",
    "# this applies the hook at inference time\n",
    "def hooked_generate(model, prompt_batch, fwd_hooks=[], generate=False, seed=None):\n",
    "    \"\"\"\n",
    "    prompt_batch takes in a list of prompts! Inference happens in parallel.\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        torch.manual_seed(seed)\n",
    "\n",
    "    with model.hooks(fwd_hooks=fwd_hooks):\n",
    "        tokenized = model.to_tokens(prompt_batch)\n",
    "        output = model.forward(input=tokenized, return_type=\"both\") # returns logits and loss\n",
    "        response = None\n",
    "\n",
    "        if generate:\n",
    "            response = model.generate(input=tokenized, max_new_tokens=5, do_sample=True) # returns generated text\n",
    "\n",
    "    return response, output\n",
    "\n",
    "\n",
    "# this acquires the steering vector for each specified layer\n",
    "def get_steering_vectors(H, steering_config):\n",
    "\n",
    "    steering_vector_per_layer = {}\n",
    "    for layer_id in steering_config[\"all_layer_ids\"]:\n",
    "        H_pos = np.array([hidden_state.cpu() for hidden_state in H[\"pos\"][layer_id]])\n",
    "        H_neg = np.array([hidden_state.cpu() for hidden_state in H[\"neg\"][layer_id]])\n",
    "\n",
    "        steering_vector = (H_pos - H_neg).mean(axis=0)\n",
    "        steering_vector_per_layer[layer_id] = torch.tensor(steering_vector, dtype=torch.float32)\n",
    "\n",
    "    return steering_vector_per_layer\n",
    "\n",
    "\n",
    "# this function retrieves the most likely answer based on the model's log-likelihood for each answer choice\n",
    "def get_most_likely_answer_via_log_likelihood(H, curr_steering_config, row, model, steering=False):\n",
    "\n",
    "    data_type = curr_steering_config[\"data_type\"]\n",
    "    question, candidates, _ = get_prompt_and_answer_choices_stereoset(row, data_type)\n",
    "\n",
    "    # Generate the prompt_batch\n",
    "    prompt_batch = [question.strip() + \" \" + candidate.strip() for candidate in candidates]\n",
    "\n",
    "    # Tokenize the prompts and the question separately\n",
    "    prompt_tokens = model.to_tokens(prompt_batch)   # This will append padding tokens to the end if the sequence is not max_len\n",
    "    question_tokens = model.to_tokens(question.strip())\n",
    "\n",
    "    if steering:\n",
    "        # Make hooks\n",
    "        hook_fn = make_steering_hook(curr_steering_config)\n",
    "\n",
    "        layer_id = curr_steering_config['layer_id']\n",
    "        editing_hooks = [(f\"blocks.{layer_id - 1}.hook_resid_pre\", hook_fn)] # the hidden_states go from 1-26. The block numbers go from 0-25\n",
    "\n",
    "        # Run with hooks\n",
    "        _, outputs = hooked_generate(model, prompt_batch, editing_hooks, generate=False, seed=42)\n",
    "        logits = outputs.logits\n",
    "    else:\n",
    "        # Run model\n",
    "        all_layer_ids = curr_steering_config[\"all_layer_ids\"]\n",
    "        outputs = model.run_with_cache(prompt_tokens) # outputs[0] --> logits, outputs[1] --> hidden_states\n",
    "\n",
    "        # Get logits and hidden_states\n",
    "        logits = outputs[0]\n",
    "\n",
    "        for layer_id in all_layer_ids:\n",
    "            # Get positive and negative examples for steering\n",
    "            stereo_idx, anti_stereo_idx, unrelated_idx = get_answer_ids(row)\n",
    "\n",
    "            hidden_states_post = outputs[1][f\"blocks.{layer_id - 1}.hook_resid_post\"]\n",
    "            stereo_output = hidden_states_post[stereo_idx].mean(axis=0)\n",
    "            anti_stereo_output = hidden_states_post[anti_stereo_idx].mean(axis=0)\n",
    "\n",
    "            H[\"pos\"][layer_id].append(anti_stereo_output)\n",
    "            H[\"neg\"][layer_id].append(stereo_output)\n",
    "\n",
    "\n",
    "    log_probs = F.log_softmax(logits, dim=-1)\n",
    "\n",
    "    # Identify the start index for the candidate tokens\n",
    "    candidate_start_idx = question_tokens.shape[1]\n",
    "    candidate_tokens = model.to_tokens(list(map(lambda x: x.strip(), candidates))) # strips all whitespaces from candidates, and puts them into a list\n",
    "\n",
    "    # Initialize results dictionary\n",
    "    total_logprob_per_candidate = {key: 0.0 for key in range(len(candidates))}\n",
    "    total_token_count_per_candidate = {key: 0 for key in range(len(candidates))}\n",
    "\n",
    "    # For each token in the candidate answer, calculate its log probability.\n",
    "    # Note: For autoregressive models, each token is predicted based on all previous tokens.\n",
    "    # Therefore, the log probability for token i (in the candidate) is taken from\n",
    "    # the model output at position (i-1) in the full sequence.\n",
    "    for pos_id, token_id in enumerate(range(candidate_tokens.shape[1]), start=candidate_start_idx):\n",
    "\n",
    "        for candidate_id in range(candidate_tokens.shape[0]):\n",
    "            curr_token = candidate_tokens[candidate_id][token_id]\n",
    "            # ignore padding tokens\n",
    "            if curr_token == 0:\n",
    "                continue\n",
    "\n",
    "            # Using i-1 because the probability of token_i is given at the previous timestep.\n",
    "            score = log_probs[candidate_id, pos_id - 1, curr_token].item()\n",
    "            total_logprob_per_candidate[candidate_id] += score\n",
    "            total_token_count_per_candidate[candidate_id] += 1\n",
    "\n",
    "    # Determine the candidate with the highest score\n",
    "    # Note: The lower the log-probability (in the negatives) the worse the answer. Thus, the answer with the log probability closest to 0\n",
    "    # (i.e. the max) is the one we want\n",
    "\n",
    "    # Since different answers have different amounts of tokens, we normalize based on amount of tokens\n",
    "    results = {key: total_logprob_per_candidate[key] / total_token_count_per_candidate[key] for key in total_token_count_per_candidate.keys()}\n",
    "    best_candidate_idx = max(results, key=results.get)\n",
    "    return results, best_candidate_idx, H\n",
    "\n",
    "\n",
    "# this obtains the results of the model pre-steering\n",
    "def prepare_steering(config, model, df):\n",
    "\n",
    "    # initialize per-layer dictionaries for the contrastive examples\n",
    "    H = {\n",
    "        \"pos\": {layer_id: [] for layer_id in config[\"all_layer_ids\"]},\n",
    "        \"neg\": {layer_id: [] for layer_id in config[\"all_layer_ids\"]}\n",
    "    }\n",
    "\n",
    "    # Get the hidden states of contrastive examples for all rows - one at a time!\n",
    "    original_responses = []\n",
    "    all_results = []\n",
    "    for row_idx in tqdm(range(len(df))):\n",
    "        row = df.iloc[row_idx]\n",
    "        results, best_candidate, H = get_most_likely_answer_via_log_likelihood(H, config, row, model, steering=False)\n",
    "        original_responses.append(best_candidate)\n",
    "        all_results.append(results)\n",
    "\n",
    "    return all_results, original_responses, H\n",
    "\n",
    "\n",
    "# this performs the steering on each specified layer\n",
    "def execute_steering(H, config, model, df):\n",
    "\n",
    "    layer_ids = config[\"all_layer_ids\"]\n",
    "    data_type = config[\"data_type\"]\n",
    "    coeff = config[\"COEFF\"]\n",
    "\n",
    "    steering_vectors_per_layer = get_steering_vectors(H, config)\n",
    "\n",
    "    results_per_layer = {}\n",
    "    prob_results_per_layer = {}\n",
    "    for layer_id in layer_ids:\n",
    "\n",
    "        # initialize dict to save model preds after steering\n",
    "        results_per_layer[layer_id] = []\n",
    "        prob_results_per_layer[layer_id] = []\n",
    "\n",
    "        # initialize steering config\n",
    "        curr_steering_config = {\n",
    "            \"all_layer_ids\": layer_ids,\n",
    "            \"layer_id\": layer_id,\n",
    "            \"data_type\": data_type,\n",
    "            \"steering_vector\": steering_vectors_per_layer[layer_id],\n",
    "            \"COEFF\": coeff,\n",
    "         }\n",
    "\n",
    "        # go through dataset one row at a time\n",
    "        for row_idx in tqdm(range(len(df))):\n",
    "            # get the new answer - after steering at given layer - from current row\n",
    "            row = df.iloc[row_idx]\n",
    "            results, best_candidate, _ = get_most_likely_answer_via_log_likelihood(H, curr_steering_config, row, model, steering=True)\n",
    "            results_per_layer[layer_id].append(best_candidate)\n",
    "            prob_results_per_layer[layer_id].append(results)\n",
    "\n",
    "    return prob_results_per_layer, results_per_layer\n",
    "\n",
    "# this evaluates how the model's preferences (measured in log-likelihood) shift after steering\n",
    "def eval_steering(df, full_results, full_results_steered, layer_id):\n",
    "    change_from_anti_to_stereo = 0\n",
    "    change_from_anti_to_unrelated = 0\n",
    "    change_from_unrelated_to_stereo = 0\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        row = df.iloc[i]\n",
    "        stereo_idx, anti_stereo_idx, unrelated_idx = get_answer_ids(row)\n",
    "        original_results = full_results[i]\n",
    "        steered_results = full_results_steered[layer_id][i]\n",
    "\n",
    "        change_from_anti_to_stereo += ((steered_results[anti_stereo_idx] - steered_results[stereo_idx]) - (original_results[anti_stereo_idx] - original_results[stereo_idx])) / len(df)\n",
    "        change_from_anti_to_unrelated += ((steered_results[anti_stereo_idx] - steered_results[unrelated_idx]) - (original_results[anti_stereo_idx] - original_results[unrelated_idx])) / len(df)\n",
    "        change_from_unrelated_to_stereo += ((steered_results[unrelated_idx] - steered_results[stereo_idx]) - (original_results[unrelated_idx] - original_results[stereo_idx])) / len(df)\n",
    "\n",
    "    return change_from_anti_to_stereo, change_from_anti_to_unrelated, change_from_unrelated_to_stereo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3dd8d4-3083-4e31-a67b-e39b383590e8",
   "metadata": {
    "id": "0b3dd8d4-3083-4e31-a67b-e39b383590e8"
   },
   "source": [
    "**4. Perform Steering**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105e738a-d8ab-4ae0-941f-1a600b08ac5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stereoset_preds = {\n",
    "    \"base\": {\n",
    "        \"inter\": {},\n",
    "        \"intra\": {}\n",
    "    },\n",
    "    \"instruct\": {\n",
    "        \"inter\": {},\n",
    "        \"intra\": {}\n",
    "    }\n",
    "}\n",
    "\n",
    "stereoset_probs = copy.deepcopy(stereoset_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8831cb52-e6a7-4864-8153-40a0d052077d",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_OF_MULTIPLE_CHOICES = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7b7dcc-5e63-4dec-a6a3-201f49421f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_grad_enabled(False)  # save memory\n",
    "if TRAIN_STATE == \"base\":\n",
    "    model = HookedTransformer.from_pretrained(\"google/gemma-2-2b\")\n",
    "else:\n",
    "    model = HookedTransformer.from_pretrained(\"google/gemma-2-2b-it\")\n",
    "\n",
    "model.eval()\n",
    "if torch.cuda.is_available():\n",
    "  model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d28e8b-051e-4657-a6dd-3c7eea5cc16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "steering_config = {\n",
    "    \"all_layer_ids\": all_layer_ids,  # for time's sake, we only steer at a few layers\n",
    "    \"data_type\": mode,\n",
    "    \"COEFF\": 400,\n",
    "}\n",
    "\n",
    "for bias_type in stereo_bias_types:\n",
    "\n",
    "    print(f\"Currently steering: {TRAIN_STATE} {mode} {bias_type}\")\n",
    "\n",
    "    # we also don't steer the entire dataset, but choose a randomized subset instead.\n",
    "    df = all_dfs[mode].sample(frac=1).reset_index(drop=True)\n",
    "    df = df[df[\"bias_type\"] == bias_type][:N_SAMPLES]\n",
    "\n",
    "    full_results, original_preds, H = prepare_steering(steering_config, model, df)\n",
    "    df[\"model_pred\"] = original_preds\n",
    "\n",
    "    full_results_steered, preds_dict = execute_steering(H, steering_config, model, df)\n",
    "\n",
    "    # Populate result (predictions) dataframe\n",
    "    result_df = pd.DataFrame.from_dict(preds_dict)\n",
    "    result_df[\"original\"] = df[\"model_pred\"].values\n",
    "    result_df[\"ans0_answer_type\"] = df[\"ans0_answer_type\"].values\n",
    "    result_df[\"ans1_answer_type\"] = df[\"ans1_answer_type\"].values\n",
    "    result_df[\"ans2_answer_type\"] = df[\"ans2_answer_type\"].values\n",
    "\n",
    "    # Populate result (change in log likelihood) dataframe\n",
    "    relative_change_in_prob_per_layer_id = {}\n",
    "    for layer_id in full_results_steered.keys():\n",
    "        s2a, u2a, s2u = eval_steering(df, full_results, full_results_steered, layer_id)\n",
    "        relative_change_in_prob_per_layer_id[layer_id] = [s2a, u2a, s2u]\n",
    "    change_in_prob_df = pd.DataFrame.from_dict(relative_change_in_prob_per_layer_id)\n",
    "    change_in_prob_df.index = [\"S2A\", \"U2A\", \"S2U\"] # stereo2anti-stereo, unrelated2anti-stereo, stereo2unrelated\n",
    "\n",
    "    stereoset_preds[TRAIN_STATE][mode][bias_type] = result_df\n",
    "    stereoset_probs[TRAIN_STATE][mode][bias_type] = change_in_prob_df\n",
    "\n",
    "print(f\"{N_SAMPLES} samples took {((time.time() - start) / 60):.2f} minutes!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6938f513-133a-420e-960a-a48250662311",
   "metadata": {
    "id": "6938f513-133a-420e-960a-a48250662311"
   },
   "source": [
    "**5. Evaluating Steering's Effect**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09a481c-4d6c-42e1-b525-fb1474b6bce1",
   "metadata": {
    "id": "f09a481c-4d6c-42e1-b525-fb1474b6bce1"
   },
   "source": [
    "#### **5.1 High-Level: Did Targeted Behavior Increase?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3a3c24-79d9-4859-8b8b-f789035137ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this computes the average ratio of post-steering to pre-steering anti-stereotypical responses\n",
    "def get_steering_effect(df, bias_type):\n",
    "\n",
    "    df = df[bias_type]\n",
    "    steered_columns = df.columns[:-4]\n",
    "\n",
    "    all_changes = []\n",
    "\n",
    "    original_answers = df.apply(lambda x: determine_answer_type_stereoset(x, pred_column=\"original\"), axis=1)\n",
    "    n_anti_answers_original = original_answers.value_counts()[2].item()\n",
    "\n",
    "    for pred_column in steered_columns:\n",
    "        new_answers = df.apply(lambda x: determine_answer_type_stereoset(x, pred_column=pred_column), axis=1)\n",
    "        n_anti_answers_new = new_answers.value_counts()[2].item()\n",
    "\n",
    "        all_changes.append(n_anti_answers_new / n_anti_answers_original)\n",
    "\n",
    "    return np.array(all_changes).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d243aac1-04cd-4605-8422-cbd54dbabeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "steering_effect_ratio = {}\n",
    "all_steering_effects = []\n",
    "\n",
    "for bias_type in stereo_bias_types:\n",
    "    effect = get_steering_effect(stereoset_preds[TRAIN_STATE][mode], bias_type)\n",
    "    all_steering_effects.append(effect)\n",
    "\n",
    "all_steering_effects = np.array(all_steering_effects)\n",
    "steering_effect_ratio[mode] = all_steering_effects.mean()\n",
    "\n",
    "print(\"Train State:\", TRAIN_STATE)\n",
    "print(\"-----------\")\n",
    "print(f\"{mode}: The ratio of anti-stereotypical answers rose by {((steering_effect_ratio[mode] - 1) * 100):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106a6d4e-cd11-4144-b6e8-3691ca953893",
   "metadata": {
    "id": "106a6d4e-cd11-4144-b6e8-3691ca953893"
   },
   "source": [
    "#### **5.2 Low-Level: Where did the Behavior Increase Come From?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7affb5bc-3b99-465c-91af-b34e716fc2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this gets the relevant values from the result dataframe\n",
    "def extract_values(df):\n",
    "\n",
    "    x_axes = df.columns\n",
    "    legend = []\n",
    "    all_probs = []\n",
    "    for idx in range(len(df)):\n",
    "        legend.append(df.iloc[idx].values[0])\n",
    "        all_probs.append(df.iloc[idx].values)\n",
    "\n",
    "    return legend, all_probs, x_axes\n",
    "\n",
    "\n",
    "def generate_plots(data_dict, bias_types, mode=None):\n",
    "    n_rows = 1\n",
    "    n_cols = len(bias_types)\n",
    "\n",
    "    fig, axes = plt.subplots(\n",
    "        n_rows, n_cols,\n",
    "        figsize=(4*n_cols, 3*n_rows),   # adjust size as needed\n",
    "        sharey=True                     # share y-axis across columns\n",
    "    )\n",
    "    plt.rcParams['text.usetex'] = True\n",
    "\n",
    "    cluster_spacing = 2.0\n",
    "    width = 0.25\n",
    "\n",
    "    for j, bias_type in enumerate(bias_types):\n",
    "        ax = axes[j]\n",
    "        df = data_dict[TRAIN_STATE][mode][bias_type]\n",
    "\n",
    "        legend, all_probs, x_axes = extract_values(df)\n",
    "\n",
    "        x = np.arange(len(x_axes)) * cluster_spacing\n",
    "\n",
    "        ax.bar(x - width, all_probs[0], width=width, color='green',  label=r\"Stereotypical $\\rightarrow$ Anti-Stereotypical\")\n",
    "        ax.bar(x,        all_probs[1], width=width, color='orange', label=r\"Unrelated $\\rightarrow$ Anti-Stereotypical\")\n",
    "        ax.bar(x + width,all_probs[2], width=width, color='blue',   label=r\"Stereotypical $\\rightarrow$ Unrelated\")\n",
    "\n",
    "        ax.axhline(0, color='black', linewidth=0.8)\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(x_axes, rotation=45, ha='right')\n",
    "\n",
    "        # only label outer edges to reduce clutter\n",
    "        if j == 0:\n",
    "            ax.set_ylabel(\"Change in Log-Likelihood\", fontsize=15)\n",
    "        ax.set_xlabel(\"Intervention Layer\", fontsize=15)\n",
    "\n",
    "        if mode:\n",
    "            if TRAIN_STATE == \"instruct\":\n",
    "                ax.set_title(f\"Fine-Tuned / {bias_type} / {mode}\", fontsize=15)\n",
    "            else:\n",
    "                ax.set_title(f\"{TRAIN_STATE.capitalize()} / {bias_type} / {mode}\", fontsize=15)\n",
    "\n",
    "        if j == 0:\n",
    "            ax.legend(loc='upper left', fontsize=11)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d1ca85-381f-49cc-a0b7-96ce9b115cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_plots(stereoset_probs, stereo_bias_types, mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ac8721-4b57-4099-b7c0-1ebdf962f4a8",
   "metadata": {
    "id": "77ac8721-4b57-4099-b7c0-1ebdf962f4a8"
   },
   "source": [
    "#### **5.2 Generation of Flow-Charts for Clearer Visualization**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b4072a-ed50-4cf0-8844-e62199484a3e",
   "metadata": {
    "id": "58b4072a-ed50-4cf0-8844-e62199484a3e"
   },
   "source": [
    "**For Changes in Prediction:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1935a52-c8fd-45be-9ea9-efcc6ff9225d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these two functions are used to compute the middle figure in figure 1. They calculate where increases/decreases in predictions come from\n",
    "def get_dict_from_matrix(mat):\n",
    "    s2a = mat[1][2] - mat[2][1]\n",
    "    s2u = mat[1][0] - mat[0][1]\n",
    "    u2a = mat[0][2] - mat[2][0]\n",
    "\n",
    "    return np.array([s2a, u2a, s2u])\n",
    "\n",
    "def get_aggregated_flow_per_bias_type(df, bias_type):\n",
    "\n",
    "    # \"U\": 0,\n",
    "    # \"S\": 1,\n",
    "    # \"A\": 2\n",
    "\n",
    "    # Gonna make a matrix!\n",
    "    # Previous answers are in the rows\n",
    "    # New answers are in the columns\n",
    "    # So: an entry in row 1 column 2 will mean that an answer S (row 1) has been steered to A (col 2)\n",
    "\n",
    "    df = df[bias_type]\n",
    "    steered_columns = df.columns[:-4]\n",
    "\n",
    "    all_changes = []\n",
    "\n",
    "    original_answers = df.apply(lambda x: determine_answer_type_stereoset(x, pred_column=\"original\"), axis=1)\n",
    "    for pred_column in steered_columns:\n",
    "        new_answers = df.apply(lambda x: determine_answer_type_stereoset(x, pred_column=pred_column), axis=1)\n",
    "\n",
    "        changes = np.zeros((3, 3))\n",
    "        for entry_idx in range(len(df)):\n",
    "            row_idx = original_answers[entry_idx]\n",
    "            col_idx = new_answers[entry_idx]\n",
    "            changes[row_idx][col_idx] += 1\n",
    "        answer_flow = get_dict_from_matrix(changes)\n",
    "        all_changes.append(answer_flow)\n",
    "\n",
    "    return np.array(all_changes) / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953486cd-1011-4998-b492-6bba3f6170a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "changes_in_preds = {}\n",
    "all_flows = []\n",
    "for bias_type in stereo_bias_types:\n",
    "    aggr_flow = get_aggregated_flow_per_bias_type(stereoset_preds[TRAIN_STATE][mode], bias_type)\n",
    "    all_flows.append(aggr_flow.mean(axis=0))\n",
    "\n",
    "all_flows = np.array(all_flows)\n",
    "all_flows.mean(axis=0)\n",
    "\n",
    "changes_in_preds[mode] = all_flows.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d8121a-f1a1-4ac8-afd2-a6952e994f24",
   "metadata": {
    "id": "64d8121a-f1a1-4ac8-afd2-a6952e994f24"
   },
   "source": [
    "**For Changes in Log-Likelihood**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b5c43a-cd92-4847-a8de-ea427bc7b756",
   "metadata": {},
   "outputs": [],
   "source": [
    "changes_in_log_likelihood = {}\n",
    "\n",
    "all_probs = []\n",
    "for bias_type in stereo_bias_types:\n",
    "    _, probs, _ = extract_values(stereoset_probs[TRAIN_STATE][mode][bias_type])\n",
    "    aggr_probs = np.array(probs).mean(axis=1)\n",
    "    all_probs.append(aggr_probs)\n",
    "\n",
    "changes_in_log_likelihood[mode] = np.array(all_probs).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63bd011-1a97-4653-a467-63a69b480505",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import FancyArrowPatch\n",
    "\n",
    "def draw_plot(data_dict, mode, title, plot=\"preds\"):\n",
    "    # -- 1) YOUR DATA HERE:\n",
    "    # Define each edge as (source, target, value, label)\n",
    "\n",
    "    edge_data = data_dict[mode]\n",
    "    edge1, edge2, edge3 = edge_data\n",
    "\n",
    "    if plot == \"preds\":\n",
    "        edges = [\n",
    "            ('Stereotypical', 'Anti-\\nStereotypical', edge1, f'{abs(edge1) * 100:.1f}\\\\%', 0, -0.05),\n",
    "            ('Unrelated', 'Anti-\\nStereotypical', edge2, f'{abs(edge2) * 100:.1f}\\\\%', +0.15, 0),\n",
    "            ('Stereotypical', 'Unrelated', edge3, f'{abs(edge3) * 100:.1f}\\\\%', -0.15, 0)\n",
    "        ]\n",
    "    else:\n",
    "        edges = [\n",
    "            ('Stereotypical', 'Anti-\\nStereotypical', edge1, f'{abs(edge1):.2f}', 0, -0.050),\n",
    "            ('Unrelated', 'Anti-\\nStereotypical', edge2, f'{abs(edge2):.2f}', +0.15, 0),\n",
    "            ('Stereotypical', 'Unrelated', edge3, f'{abs(edge3):.2f}', -0.15, 0)\n",
    "        ]\n",
    "\n",
    "    # -- 2) LINEWIDTH SCALING PARAMETERS:\n",
    "    min_width, max_width = 0.8, 5\n",
    "    values = [edge[2] for edge in edges]\n",
    "    min_val, max_val = min(values), max(values)\n",
    "\n",
    "    def scale_width(val):\n",
    "        \"\"\"Linearly scale val between min_width and max_width.\"\"\"\n",
    "        if max_val == min_val:\n",
    "            return (min_width + max_width) / 2\n",
    "        return min_width + (val - min_val) / (max_val - min_val) * (max_width - min_width)\n",
    "\n",
    "    # -- 3) NODE POSITIONS (adjust as you like):\n",
    "    pos = {\n",
    "        'Stereotypical': (0, 0.5, \"gainsboro\"),\n",
    "        'Anti-\\nStereotypical': (1, 0.5, \"gainsboro\"),\n",
    "        'Unrelated': (0.5, 0.1, \"white\")\n",
    "    }\n",
    "\n",
    "    # -- 4) PLOTTING:\n",
    "    fig, ax = plt.subplots(\n",
    "        figsize=(3.5, 3)\n",
    "    )\n",
    "\n",
    "    # Draw nodes\n",
    "    for node, (x, y, color) in pos.items():\n",
    "        ax.scatter(x, y, s=2600, zorder=2, color=color, edgecolors=\"gray\", linewidths=0.5)\n",
    "        ax.text(x, y, node, ha='center', va='center',\n",
    "                color='black', fontweight='bold', zorder=3)\n",
    "\n",
    "    # Draw directed edges\n",
    "    for src, tgt, val, lbl, _x, _y in edges:\n",
    "\n",
    "        if src == \"Unrelated\" and tgt == \"Anti-\\nStereotypical\":\n",
    "            color = \"red\"\n",
    "        elif val < 0:\n",
    "            color = \"red\"\n",
    "        else:\n",
    "            color = \"green\"\n",
    "\n",
    "        if val > 0:\n",
    "            start = pos[src]\n",
    "            end   = pos[tgt]\n",
    "        else:\n",
    "            start = pos[tgt]\n",
    "            end   = pos[src]\n",
    "            val *= -1\n",
    "\n",
    "        lw = scale_width(val)\n",
    "        arrow = FancyArrowPatch(\n",
    "            start, end,\n",
    "            arrowstyle='-|>',         # triangular arrowhead\n",
    "            mutation_scale=15,        # arrowhead size\n",
    "            linewidth=lw,\n",
    "            color=color,\n",
    "            shrinkA=30, shrinkB=30,\n",
    "            zorder=1\n",
    "        )\n",
    "        ax.add_patch(arrow)\n",
    "\n",
    "        # Label at midpoint\n",
    "        mx, my = (start[0]+end[0])/2 + _x, (start[1]+end[1])/2 + _y\n",
    "        ax.text(mx, my, lbl,\n",
    "                ha='center', va='center',\n",
    "                fontstyle='italic', zorder=4)\n",
    "\n",
    "    # Clean up\n",
    "    ax.set_xlim(-0.2, 1.2)\n",
    "    ax.set_ylim(0, 0.6)\n",
    "    ax.axis('off')\n",
    "    plt.title(f\"{title}\\n{TRAIN_STATE} - {mode}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1487c0ac-1458-4c04-99bb-46e2028236dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_plot(changes_in_preds, \"inter\", \"Changes in Predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08eae75-d4f7-4772-952e-f513b197a9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_plot(changes_in_log_likelihood, \"inter\", \"Changes in Log-Likelihood\", plot=\"probs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f14d52-34db-4711-bc40-1314383b6412",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
