{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "HK3uw5q3EyPL"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Edge Cases in Expressivity\n",
        "\n",
        "In this notebook we show the results of the offset prediction experiments on single layer S4D and Mamba models. The models  have been trained on time series of length 200 for at most 100 epochs each. The checkpoints we use here are the `best` with respect to predicting the offset.\n",
        "\n",
        "Here we provide results for the following experiments in the paper:\n",
        "\n",
        "\n",
        "1.   Offset Prediction\n",
        "2.   Consecutive ISI Phase Alignment Test (generalization test)\n",
        "3.   Double ISI Phase Alignment Test ((generalization test)\n",
        "\n",
        "\n",
        "This notebook takes ~30 mins to run. ~15 mins to train each model.\n"
      ],
      "metadata": {
        "id": "bjANxGBFzNp9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download S4D and Mamba code"
      ],
      "metadata": {
        "id": "PMcdmKir9kYk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! wget -O s4.py https://raw.githubusercontent.com/state-spaces/s4/refs/heads/main/models/s4/s4.py\n",
        "! wget -O mamba.py https://raw.githubusercontent.com/johnma2006/mamba-minimal/refs/heads/master/model.py\n",
        "! sed '27,152d' s4.py > tmp && mv tmp s4.py\n",
        "! grep -v 'lightning' s4.py > tmp && mv tmp s4.py"
      ],
      "metadata": {
        "id": "x7ttMSExklCo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import csv\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import wandb\n",
        "from pathlib import Path\n",
        "from mamba import Mamba, ModelArgs\n",
        "from s4 import *"
      ],
      "metadata": {
        "id": "Cz3Y_jLO1qwA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## S4D"
      ],
      "metadata": {
        "id": "tHjjW6rJ9hhL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class S4DLayer(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        d_model,\n",
        "        d_state,\n",
        "        channels=1,\n",
        "        activation=\"gelu\",\n",
        "        dropout=0.0,\n",
        "        use_residual=True,\n",
        "        **ssm_kwargs\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.kernel = SSMKernelDiag(\n",
        "            d_model=d_model, d_state=d_state, channels=channels, **ssm_kwargs\n",
        "        )\n",
        "        self.channel_mixer = nn.Linear(channels * d_model, d_model)\n",
        "        self.activation = Activation(activation)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.norm = nn.LayerNorm(d_model)\n",
        "        self.use_residual = use_residual\n",
        "        self.d_model = d_model\n",
        "        self.d_state = d_state\n",
        "        self.channels = channels\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: shape (b, l, d)\n",
        "\n",
        "        Returns:\n",
        "            output: shape (b, l, d)\n",
        "        \"\"\"\n",
        "        self.kernel._setup_step()\n",
        "        B, L, d = x.shape\n",
        "        state = self.default_state(B)\n",
        "        outputs = []\n",
        "        for t in range(L):\n",
        "            x_t = x[:, t]  # (b, d)\n",
        "            y_t, state = self.kernel.step(x_t, state)\n",
        "            outputs.append(y_t)\n",
        "        y = torch.concatenate(outputs, dim=1)  # (b, l, d)\n",
        "        y = self.channel_mixer(y)\n",
        "        y = self.activation(y)\n",
        "        y = self.dropout(y)\n",
        "        if self.use_residual:\n",
        "            y = y + x\n",
        "        y = self.norm(y)\n",
        "        return y\n",
        "\n",
        "    def default_state(self, batch_size):\n",
        "        return self.kernel.default_state(batch_size)\n",
        "\n",
        "\n",
        "class S4D(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        vocab_size,\n",
        "        d_model,\n",
        "        d_state,\n",
        "        n_layers,\n",
        "        activation=\"gelu\",\n",
        "        dropout=0.0,\n",
        "        use_residual=True,\n",
        "        **ssm_kwargs\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.output_proj = nn.Linear(d_model, vocab_size)\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
        "\n",
        "        self.seq = nn.Sequential(\n",
        "            *[\n",
        "                S4DLayer(\n",
        "                    d_model=d_model,\n",
        "                    d_state=d_state,\n",
        "                    activation=activation,\n",
        "                    dropout=dropout,\n",
        "                    use_residual=use_residual,\n",
        "                    **ssm_kwargs\n",
        "                )\n",
        "                for _ in range(n_layers)\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        self.vocab_size = vocab_size\n",
        "        self.d_model = d_model\n",
        "        self.d_state = d_state\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: shape (b, l)\n",
        "\n",
        "        Returns:\n",
        "            y: shape (b, l, vocab_size)\n",
        "        \"\"\"\n",
        "        x = self.embedding(x)  # (b, l, d)\n",
        "        x = self.seq(x)\n",
        "        x = self.output_proj(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "HHfekyLIwIcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Offset Prediction"
      ],
      "metadata": {
        "id": "6EzDXVb8Mszk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper Code"
      ],
      "metadata": {
        "id": "HK3uw5q3EyPL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class AlternatingSignalDataset(Dataset):\n",
        "    def __init__(self, inputs, targets):\n",
        "        self.inputs = inputs\n",
        "        self.targets = targets\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.inputs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.inputs[idx], self.targets[idx]\n",
        "\n",
        "def generate_trace_task(num_seq=1000, n=200, two_peaks=False, holdout_intervals=None):\n",
        "    holdout_inputs = []\n",
        "    holdout_targets = []\n",
        "    inputs = []\n",
        "    targets = []\n",
        "    # two_peaks = False\n",
        "    # np.random.seed(102002)\n",
        "\n",
        "    for seq_num in range(num_seq):\n",
        "        signal = []\n",
        "        length = 0\n",
        "\n",
        "        # Set on/off lengths and peak distances based on `n`\n",
        "        if n == 200 or n == 300 or n == 400:\n",
        "            if not two_peaks:\n",
        "                off_length = np.random.randint(20, 40)\n",
        "                on_length = 20\n",
        "            else:\n",
        "                # off_length = np.random.randint(20, 70)\n",
        "                off_length = 20\n",
        "                peak_distance = 50\n",
        "                on_length = 10\n",
        "\n",
        "        elif n == 600:\n",
        "            if not two_peaks:\n",
        "                off_length = np.random.randint(60, 120)\n",
        "                on_length = 60\n",
        "\n",
        "            else:\n",
        "                off_length = 200\n",
        "                peak_distance = 200\n",
        "                on_length = 30\n",
        "\n",
        "        elif n == 1000:\n",
        "            if not two_peaks:\n",
        "                off_length = np.random.randint(100, 200)\n",
        "                on_length = 100\n",
        "\n",
        "            else:\n",
        "                off_length = 400\n",
        "                peak_distance = 400\n",
        "\n",
        "                on_length = 50\n",
        "        else:\n",
        "            raise ValueError(\"Unsupported value of n. Choose 200, 600, or 1000.\")\n",
        "\n",
        "        # Generate the signal with one or two peaks based on `two_peaks`\n",
        "        signal.extend([0] * off_length)\n",
        "        signal.extend([1] * on_length)\n",
        "\n",
        "        if two_peaks:\n",
        "            # Add the specified distance between peaks, followed by the second peak\n",
        "            signal.extend([0] * peak_distance)\n",
        "            signal.extend([1] * on_length)\n",
        "\n",
        "        # Fill with 0s until the signal length matches `n`\n",
        "        signal.extend([0] * (n - len(signal)))\n",
        "\n",
        "        # Trim in case signal exceeds `n` (shouldn’t normally happen with the fill above)\n",
        "        # print('length of signal: ', len(signal))\n",
        "        signal = signal[:n]\n",
        "\n",
        "        # Convert signal to tensor format\n",
        "        ts = torch.tensor(signal, dtype=torch.long)\n",
        "\n",
        "        # Create input and target sequences\n",
        "        input_seq = ts\n",
        "        target_seq = torch.cat((torch.tensor([0]*1, dtype=torch.long), ts[:-10]), dim=0)\n",
        "        # print('input shape: ', input_seq.shape)\n",
        "\n",
        "        # Check if the current sequence is part of the holdout intervals\n",
        "        if holdout_intervals and seq_num in holdout_intervals:\n",
        "            holdout_inputs.append(input_seq)\n",
        "            holdout_targets.append(target_seq)\n",
        "        else:\n",
        "            inputs.append(input_seq)\n",
        "            targets.append(target_seq)\n",
        "\n",
        "    # print(f'\\nNUMBER OF INPUTS {torch.stack(holdout_inputs).shape}\\n')\n",
        "    # print(f'\\nShape of inputs: {torch.stack(inputs).shape}')\n",
        "    return torch.stack(targets), torch.stack(inputs), torch.stack(holdout_targets), torch.stack(holdout_inputs)\n",
        "\n",
        "\n",
        "def generate_inter_trial_interval(num_seq=1000, n=200, iti=(20, 40), isi=10, holdout_intervals=None):\n",
        "    '''\n",
        "    Generate data to train S4D model.\n",
        "    Data is of the form: initially off for (20-40) time steps,\n",
        "    then on for 10 time steps, and repeats.\n",
        "    The length of the signals should be 200 time steps.\n",
        "    '''\n",
        "    holdout_inputs = []\n",
        "    holdout_targets = []\n",
        "    inputs = []\n",
        "    targets = []\n",
        "\n",
        "    for seq_num in range(num_seq):\n",
        "        signal = []\n",
        "        length = 0\n",
        "\n",
        "        while length < n:\n",
        "            # off_length = np.random.randint(20, 40)\n",
        "            off_length = np.random.randint(iti[0], iti[1])\n",
        "            # off_length = np.random.randint(2, 8)\n",
        "\n",
        "            # on_length = 10\n",
        "            on_length = isi\n",
        "            # on_length = 2\n",
        "            signal.extend([0] * off_length)\n",
        "            signal.extend([1] * on_length)\n",
        "            length += off_length + on_length\n",
        "\n",
        "        signal = signal[:n]\n",
        "        ts = torch.tensor(signal, dtype=torch.long)\n",
        "\n",
        "        # Create input and target sequences\n",
        "        input_seq = ts\n",
        "        target_seq = torch.cat((ts[1:], torch.tensor([0], dtype=torch.long)), dim=0)\n",
        "\n",
        "        # Check if the current sequence is part of the holdout intervals\n",
        "        if holdout_intervals and seq_num in holdout_intervals:\n",
        "            holdout_inputs.append(input_seq)\n",
        "            holdout_targets.append(target_seq)\n",
        "        else:\n",
        "            inputs.append(input_seq)\n",
        "            targets.append(target_seq)\n",
        "\n",
        "    return torch.stack(inputs), torch.stack(targets), torch.stack(holdout_inputs), torch.stack(holdout_targets)\n",
        "\n",
        "def get_offset_indices(signal):\n",
        "    \"\"\"\n",
        "    Find all indices where ISI turns off (transitions from 1 to 0) in a signal.\n",
        "\n",
        "    Args:\n",
        "        signal: A torch.Tensor of shape [200] or similar 1D tensor\n",
        "\n",
        "    Returns:\n",
        "        List of integers representing indices where the signal transitions from 1 to 0\n",
        "    \"\"\"\n",
        "    # Ensure we're working with a 1D tensor with proper values\n",
        "    if torch.is_tensor(signal):\n",
        "        # If tensor has extra dimensions, flatten it\n",
        "        if signal.dim() > 1:\n",
        "            signal = signal.flatten()\n",
        "\n",
        "        # Convert to numpy for easier processing\n",
        "        signal_np = signal.detach().cpu().numpy()\n",
        "    else:\n",
        "        # If it's already a numpy array or list\n",
        "        signal_np = np.array(signal)\n",
        "\n",
        "    # Find transitions from 1 to 0\n",
        "    # Using numpy operations for efficiency\n",
        "    transitions = np.diff(signal_np.astype(int))\n",
        "    # A transition from 1 to 0 will have a difference of -1\n",
        "    offset_indices = np.where(transitions == -1)[0] + 1  # +1 because diff gives index before transition\n",
        "\n",
        "    return offset_indices.tolist()\n",
        "\n",
        "\n",
        "def get_offset_indices_batched(signals):\n",
        "    \"\"\"\n",
        "    Find all indices where ISI turns off (transitions from 1 to 0) for a batch of signals.\n",
        "\n",
        "    Args:\n",
        "        signals: A torch.Tensor of shape [batch_size, sequence_length], e.g., [8, 200]\n",
        "\n",
        "    Returns:\n",
        "        List of lists, where each inner list contains the offset indices for one signal in the batch\n",
        "    \"\"\"\n",
        "    if not torch.is_tensor(signals):\n",
        "        signals = torch.tensor(signals)\n",
        "\n",
        "    # Ensure the tensor is on CPU for numpy conversion\n",
        "    if signals.device.type != 'cpu':\n",
        "        signals = signals.detach().cpu()\n",
        "\n",
        "    # Initialize list to store offsets for each signal in the batch\n",
        "    batch_offsets = []\n",
        "\n",
        "    # Process each signal in the batch\n",
        "    for i in range(signals.shape[0]):\n",
        "        # Extract single signal\n",
        "        signal = signals[i]\n",
        "\n",
        "        # Convert to numpy\n",
        "        signal_np = signal.numpy()\n",
        "\n",
        "        # Find transitions from 1 to 0 using numpy diff\n",
        "        transitions = np.diff(signal_np.astype(int))\n",
        "\n",
        "        # A transition from 1 to 0 will have a difference of -1\n",
        "        offset_indices = np.where(transitions == -1)[0] + 1  # +1 because diff gives index before transition\n",
        "\n",
        "        # Store the offsets for this signal\n",
        "        batch_offsets.append(offset_indices.tolist())\n",
        "\n",
        "    return batch_offsets\n",
        "\n",
        "\n",
        "def get_flat_batch_indices(batch_tensor):\n",
        "    \"\"\"\n",
        "    Get flat (batch_idx, seq_idx) pairs for all ISI offset points.\n",
        "\n",
        "    Args:\n",
        "        batch_tensor: A torch.Tensor of shape [batch_size, sequence_length]\n",
        "\n",
        "    Returns:\n",
        "        Two numpy arrays:\n",
        "        - batch_indices: array of batch indices\n",
        "        - seq_indices: array of sequence indices where ISI turns off\n",
        "    \"\"\"\n",
        "    # Get lists of offset indices for each sequence in the batch\n",
        "    batch_offsets = get_offset_indices_batched(batch_tensor)\n",
        "\n",
        "    # Prepare flat arrays\n",
        "    batch_indices = []\n",
        "    seq_indices = []\n",
        "\n",
        "    # Collect all (batch_idx, seq_idx) pairs\n",
        "    for batch_idx, offsets in enumerate(batch_offsets):\n",
        "        for seq_idx in offsets:\n",
        "            batch_indices.append(batch_idx)\n",
        "            seq_indices.append(seq_idx)\n",
        "\n",
        "    return np.array(batch_indices), np.array(seq_indices)\n",
        "\n",
        "\n",
        "def check_batch_match_at_offset(binary_output, targets, match_threshold=0.5):\n",
        "    \"\"\"\n",
        "    Checks if at least half of the batch from binary output matches the target at offset indices.\n",
        "\n",
        "    Args:\n",
        "        binary_output: Tensor of shape [batch_size, sequence_length] with binary values (0 or 1)\n",
        "        targets: Tensor of shape [batch_size, sequence_length] or [batch_size, sequence_length, 1]\n",
        "        match_threshold: Minimum fraction of matches required (default: 0.5 means at least 50%)\n",
        "\n",
        "    Returns:\n",
        "        tuple: (match_ratio, match_result, match_details)\n",
        "            - match_ratio: Fraction of sequences with matching offsets\n",
        "            - match_result: Boolean indicating if match_ratio >= match_threshold\n",
        "            - match_details: Dictionary with detailed information about matches\n",
        "    \"\"\"\n",
        "    # Get batched offset indices\n",
        "    batch_offsets = get_offset_indices_batched(targets.squeeze())\n",
        "\n",
        "\n",
        "    # Make sure targets has same shape as binary_output\n",
        "    if targets.dim() > binary_output.dim():\n",
        "        targets = targets.squeeze(-1)\n",
        "\n",
        "    # Move tensors to CPU for processing\n",
        "    if binary_output.device.type != 'cpu':\n",
        "        binary_output = binary_output.detach().cpu()\n",
        "    if targets.device.type != 'cpu':\n",
        "        targets = targets.detach().cpu()\n",
        "\n",
        "    # Initialize counters\n",
        "    batch_size = binary_output.shape[0]\n",
        "    sequences_with_matches = 0\n",
        "    total_offsets = 0\n",
        "    total_matches = 0\n",
        "    match_details = {}\n",
        "\n",
        "    # Check each sequence in the batch\n",
        "    for batch_idx, offsets in enumerate(batch_offsets):\n",
        "        if not offsets:  # Skip if no offsets found\n",
        "            match_details[f\"sequence_{batch_idx}\"] = {\n",
        "                \"offsets\": 0,\n",
        "                \"matches\": 0,\n",
        "                \"match_ratio\": 0,\n",
        "                \"status\": \"no_offsets\"\n",
        "            }\n",
        "            continue\n",
        "\n",
        "        # Count matches for this sequence\n",
        "        sequence_matches = 0\n",
        "        sequence_details = []\n",
        "\n",
        "        for offset_idx in offsets:\n",
        "            # The actual offset where ISI turns off\n",
        "            offset = offset_idx\n",
        "\n",
        "            # Check if value at offset matches in target\n",
        "            # We expect 0 at offset since that's where ISI turns off\n",
        "            # But we check preceding value to see if target also turns off at same point\n",
        "            if offset > 0 and offset < binary_output.shape[1]:\n",
        "                # Get the value before the transition (should be 1)\n",
        "                prev_binary = binary_output[batch_idx, offset-1].item()\n",
        "                prev_target = targets[batch_idx, offset-1].item()\n",
        "\n",
        "                # Get the value at the transition (should be 0)\n",
        "                curr_binary = binary_output[batch_idx, offset].item()\n",
        "                curr_target = targets[batch_idx, offset].item()\n",
        "\n",
        "                # Check if pattern matches: 1→0 transition in both binary_output and target\n",
        "                transition_match = (prev_binary > 0.5 and prev_target > 0.5 and\n",
        "                                    curr_binary < 0.5 and curr_target < 0.5)\n",
        "\n",
        "                if transition_match:\n",
        "                    sequence_matches += 1\n",
        "\n",
        "                sequence_details.append({\n",
        "                    \"offset\": offset,\n",
        "                    \"binary_before\": prev_binary,\n",
        "                    \"target_before\": prev_target,\n",
        "                    \"binary_at\": curr_binary,\n",
        "                    \"target_at\": curr_target,\n",
        "                    \"match\": transition_match\n",
        "                })\n",
        "\n",
        "        # Calculate match ratio for this sequence\n",
        "        seq_match_ratio = sequence_matches / len(offsets) if offsets else 0\n",
        "        sequence_has_match = seq_match_ratio >= match_threshold\n",
        "\n",
        "        if sequence_has_match:\n",
        "            sequences_with_matches += 1\n",
        "\n",
        "        # Store sequence details\n",
        "        match_details[f\"sequence_{batch_idx}\"] = {\n",
        "            \"offsets\": len(offsets),\n",
        "            \"matches\": sequence_matches,\n",
        "            \"match_ratio\": seq_match_ratio,\n",
        "            \"status\": \"match\" if sequence_has_match else \"no_match\",\n",
        "            \"details\": sequence_details\n",
        "        }\n",
        "\n",
        "        # Update totals\n",
        "        total_offsets = len(offsets)\n",
        "        total_matches += sequence_matches\n",
        "\n",
        "    # Calculate overall match ratio\n",
        "    batch_match_ratio = sequences_with_matches / batch_size if batch_size > 0 else 0\n",
        "    overall_match_ratio = total_matches / total_offsets if total_offsets > 0 else 0\n",
        "\n",
        "    # Add summary to match details\n",
        "    match_details[\"summary\"] = {\n",
        "        \"batch_size\": batch_size,\n",
        "        \"sequences_with_matches\": sequences_with_matches,\n",
        "        \"batch_match_ratio\": batch_match_ratio,\n",
        "        \"total_offsets\": total_offsets,\n",
        "        \"total_matches\": total_matches,\n",
        "        \"overall_match_ratio\": overall_match_ratio,\n",
        "        \"threshold_met\": batch_match_ratio >= match_threshold\n",
        "    }\n",
        "\n",
        "    return batch_match_ratio, batch_match_ratio >= match_threshold, match_details\n",
        "\n",
        "\n",
        "# Split train data into train and validation sets\n",
        "def split_train_val_og(train_inputs, train_targets, val_split=0.1):\n",
        "    dataset_size = len(train_inputs)\n",
        "    indices = list(range(dataset_size))\n",
        "    split = int(np.floor(val_split * dataset_size))\n",
        "\n",
        "    np.random.shuffle(indices)\n",
        "\n",
        "    train_indices, val_indices = indices[split:], indices[:split]\n",
        "\n",
        "    train_inputs_split = train_inputs[train_indices]\n",
        "    train_targets_split = train_targets[train_indices]\n",
        "\n",
        "    val_inputs_split = train_inputs[val_indices]\n",
        "    val_targets_split = train_targets[val_indices]\n",
        "\n",
        "    return train_inputs_split, train_targets_split, val_inputs_split, val_targets_split\n",
        "\n",
        "\n",
        "\n",
        "# split dataset into train and validation sets\n",
        "def split_train_val(train, val_split):\n",
        "    train_len = int(len(train) * (1.0-val_split))\n",
        "    train, val = torch.utils.data.random_split(\n",
        "        train,\n",
        "        (train_len, len(train) - train_len),\n",
        "        generator=torch.Generator().manual_seed(42),\n",
        "    )\n",
        "    return train, val\n",
        "\n",
        "\n",
        "\n",
        "def visualize_signals(input_signal, target_signal):\n",
        "\n",
        "    fig, ax = plt.subplots(ncols=1, nrows=1, constrained_layout=True, figsize=(8, 8))\n",
        "\n",
        "    # ax = axes[0]\n",
        "    # ax.plot(input_signal.numpy(), 'r', label=' ITI ')\n",
        "    # ax.plot(target_signal.numpy(), 'b', label=' ISI ')\n",
        "\n",
        "    ax.plot(input_signal.numpy(), 'r', label='Input')\n",
        "    ax.plot(target_signal.numpy(), 'b', label='Target')\n",
        "\n",
        "    # labelLines(ax.get_lines(), zorder=5.5, color='r')\n",
        "\n",
        "\n",
        "    plt.legend()\n",
        "    plt.title('Input Signal')\n",
        "    plt.xlabel('Time Step')\n",
        "    plt.ylabel('Value')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    # plt.savefig('./test_out.png')\n",
        "\n",
        "\n",
        "def train(model, dataloader, device, optimizer, criterion, model_name, grad_clip,\n",
        "          mse_log, loss_log):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    for batch_inputs, batch_targets in dataloader:\n",
        "        batch_inputs = batch_inputs.to(device)\n",
        "        batch_targets = batch_targets.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if model_name == 'Transformer':\n",
        "            seq_len = batch_inputs.size(1)\n",
        "            src_mask = nn.Transformer.generate_square_subsequent_mask(seq_len).to(device)\n",
        "            predictions = model(batch_inputs, src_mask=src_mask)\n",
        "        else:\n",
        "            predictions = model(batch_inputs)\n",
        "\n",
        "        num_classes = predictions.shape[-1]\n",
        "        loss = criterion(predictions.view(-1, num_classes), batch_targets.view(-1))\n",
        "        loss.backward()\n",
        "\n",
        "        if grad_clip:\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        loss_log.append(loss.item())\n",
        "\n",
        "        # Compute MSE for class 1 probability (for binary classification)\n",
        "        probs_class1 = torch.softmax(predictions, dim=-1)[..., 1]\n",
        "        mse = F.mse_loss(probs_class1, batch_targets.float()).item()\n",
        "        mse_log.append(mse)\n",
        "\n",
        "        # Accuracy computation\n",
        "        predicted_classes = predictions.argmax(dim=-1)\n",
        "        total_correct += (predicted_classes == batch_targets).sum().item()\n",
        "        total_samples += batch_targets.numel()\n",
        "\n",
        "    average_loss = total_loss / len(dataloader)\n",
        "    accuracy = total_correct / total_samples if total_samples > 0 else 0.0\n",
        "\n",
        "    return average_loss, accuracy\n",
        "\n",
        "\n",
        "def eval(model, valloader, device, criterion, epoch, model_name, clip_grad):\n",
        "    model.eval()\n",
        "    eval_loss = 0\n",
        "    total = 0\n",
        "    total_batches = len(valloader)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_ind, (inputs, targets) in enumerate(valloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            if model_name == 'Transformer':\n",
        "                src_mask = nn.Transformer.generate_square_subsequent_mask(inputs.size(1)).to(device)\n",
        "                outputs = model(inputs, src_mask=src_mask)\n",
        "            else:\n",
        "                outputs = model(inputs)\n",
        "\n",
        "            d_output = outputs.shape[-1]\n",
        "            loss = criterion(outputs.view(-1, d_output), targets.view(-1))\n",
        "            mse = F.mse_loss(torch.softmax(outputs, dim=-1)[..., 1], targets).item()\n",
        "\n",
        "            eval_loss += loss.item()\n",
        "            total += inputs.size(0)\n",
        "\n",
        "    avg_loss = eval_loss / total_batches\n",
        "    # print(f\"Epoch {epoch} - Eval Loss: {avg_loss:.4f}\")\n",
        "\n",
        "\n",
        "def setup_optimizer(model, lr, weight_decay, epochs):\n",
        "    \"\"\"\n",
        "    S4 requires a specific optimizer setup.\n",
        "\n",
        "    The S4 layer (A, B, C, dt) parameters typically\n",
        "    require a smaller learning rate (typically 0.001), with no weight decay.\n",
        "\n",
        "    The rest of the model can be trained with a higher learning rate (e.g. 0.004, 0.01)\n",
        "    and weight decay (if desired).\n",
        "    \"\"\"\n",
        "\n",
        "    # All parameters in the model\n",
        "    all_parameters = list(model.parameters())\n",
        "\n",
        "    # print('all parameters: ', all_parameters)\n",
        "\n",
        "    # General parameters don't contain the special _optim key\n",
        "    params = [p for p in all_parameters if not hasattr(p, \"_optim\")]\n",
        "\n",
        "    # Create an optimizer with the general parameters\n",
        "    optimizer = optim.AdamW(params, lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "    # Add parameters with special hyperparameters\n",
        "    hps = [getattr(p, \"_optim\") for p in all_parameters if hasattr(p, \"_optim\")]\n",
        "    hps = [\n",
        "        dict(s) for s in sorted(list(dict.fromkeys(frozenset(hp.items()) for hp in hps)))\n",
        "    ]  # Unique dicts\n",
        "    for hp in hps:\n",
        "        params = [p for p in all_parameters if getattr(p, \"_optim\", None) == hp]\n",
        "        optimizer.add_param_group(\n",
        "            {\"params\": params, **hp}\n",
        "        )\n",
        "\n",
        "    # Create a lr scheduler\n",
        "    # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=patience, factor=0.2)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n",
        "\n",
        "    # Print optimizer info\n",
        "    keys = sorted(set([k for hp in hps for k in hp.keys()]))\n",
        "    for i, g in enumerate(optimizer.param_groups):\n",
        "        group_hps = {k: g.get(k, None) for k in keys}\n",
        "        print(' | '.join([\n",
        "            f\"Optimizer group {i}\",\n",
        "            f\"{len(g['params'])} tensors\",\n",
        "        ] + [f\"{k} {v}\" for k, v in group_hps.items()]))\n",
        "\n",
        "    return optimizer, scheduler\n",
        "\n",
        "\n",
        "\n",
        "def see_all():\n",
        "    '''\n",
        "    viz all train and test data in one image\n",
        "    '''\n",
        "\n",
        "    test_ckpt = torch.load('./datasets/trace/test.pth')\n",
        "\n",
        "\n",
        "    # print(test_ckpt.dataset.__len__())\n",
        "    test_inputs = test_ckpt.dataset.inputs\n",
        "    test_targets = test_ckpt.dataset.targets\n",
        "    # Number of subplots (assuming you want one plot for each input-target pair)\n",
        "    num_plots = len(test_inputs) + len(test_targets)\n",
        "\n",
        "    # Determine grid size (e.g., square or close to square)\n",
        "    grid_size = int(np.ceil(np.sqrt(num_plots)))\n",
        "\n",
        "    # Create subplots grid\n",
        "    fig, axes = plt.subplots(grid_size, grid_size, figsize=(15, 15))  # Adjust the figsize as needed\n",
        "    axes = axes.flatten()  # Flatten in case grid_size doesn't match perfectly\n",
        "\n",
        "    # Plot each input in a separate subplot\n",
        "    for idx, inputs in enumerate(test_inputs):\n",
        "        axes[idx].plot(inputs)\n",
        "        axes[idx].set_title(f'Input {idx+1}')\n",
        "\n",
        "    # Plot each target in a separate subplot, continuing from where inputs left off\n",
        "    for idx, targets in enumerate(test_targets):\n",
        "        axes[len(test_inputs) + idx].plot(targets)\n",
        "        axes[len(test_inputs) + idx].set_title(f'Target {idx+1}')\n",
        "\n",
        "    # Hide any remaining empty subplots if number of plots isn't a perfect square\n",
        "    for ax in axes[num_plots:]:\n",
        "        ax.axis('off')\n",
        "\n",
        "    plt.tight_layout()  # Ensure plots are neatly organized\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def model_params(seed, model_checkpoint, model_type, hidden, output_file):\n",
        "\n",
        "    num_layers = 1\n",
        "    input_size = 1\n",
        "    hidden_size = int(hidden)\n",
        "\n",
        "    # Print the model details (optional)\n",
        "    print(model_type, input_size, hidden_size, num_layers)\n",
        "\n",
        "    # Initialize the model (assuming get_model is defined elsewhere)\n",
        "    model = get_model(model_type, input_size, hidden_size, num_layers)\n",
        "\n",
        "    # Load model from checkpoint\n",
        "    checkpoint = torch.load(model_checkpoint, weights_only='False')\n",
        "\n",
        "    # Check if the checkpoint contains 'model_state_dict'\n",
        "    if 'model_state_dict' in checkpoint:\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        total_params = sum(p.numel() for p in model.parameters())\n",
        "        print(f\"Total number of parameters: {total_params}\")\n",
        "    else:\n",
        "        print(\"Checkpoint does not contain 'model_state_dict'.\")\n",
        "        total_params = 'N/A'  # Default value if state_dict is not found\n",
        "\n",
        "    # Prepare data to write into the CSV file\n",
        "    data = [model_type, input_size, hidden_size, num_layers, total_params, seed]\n",
        "\n",
        "    # Write the parameters into the CSV file\n",
        "    with open(output_file, mode='a', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "\n",
        "        # Check if file is empty to write the header\n",
        "        file.seek(0, 2)  # Move the pointer to the end of the file\n",
        "        if file.tell() == 0:\n",
        "            writer.writerow(['Model Type', 'Input Size', 'Hidden Size', 'Num Layers', 'Total Params', 'Seed'])\n",
        "\n",
        "        # Write the model details\n",
        "        writer.writerow(data)\n",
        "\n",
        "    print(f\"Model parameters saved to {output_file}.\")"
      ],
      "metadata": {
        "id": "Ij1iDQMHE1lC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model_eval.py\n",
        "\n",
        "\"\"\"\n",
        "Model Evaluation Module\n",
        "Easy-to-import module for running model evaluations in Google Colab\n",
        "\"\"\"\n",
        "\n",
        "from pathlib import Path\n",
        "import re\n",
        "import torch\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "import os\n",
        "from typing import Dict, Tuple, Optional, Union, List\n",
        "import ast\n",
        "\n",
        "\n",
        "def get_model(model_name, vocab_size, hidden_size, state_size, num_layers):\n",
        "    \"\"\"Initialize and return a model based on the model name.\"\"\"\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "    if model_name == 'S4D':\n",
        "        if S4D is None:\n",
        "            raise ImportError(\"S4D model class not available\")\n",
        "        # model = S4D(\n",
        "        #     d_model=hidden_size,\n",
        "        #     n_layers=num_layers,\n",
        "        #     n_vocab=vocab_size,\n",
        "        #     dropout=0,\n",
        "        #     d_state=state_size,\n",
        "        #     embed=True\n",
        "        # )\n",
        "        model = S4D(\n",
        "            vocab_size=vocab_size,\n",
        "            d_model=hidden_size,\n",
        "            d_state=state_size,\n",
        "            n_layers=num_layers,\n",
        "            dt_min=0.001,\n",
        "            dt_max=0.1,\n",
        "            init='legs'\n",
        "        )\n",
        "    elif model_name == 'MAMBA':\n",
        "        if Mamba is None:\n",
        "            raise ImportError(\"Mamba model class not available\")\n",
        "        d_model = hidden_size\n",
        "        d_state = state_size\n",
        "        n_layers = num_layers\n",
        "        model_args = ModelArgs(d_model, n_layers, vocab_size, d_state, pad_vocab_size_multiple=1)\n",
        "        print(model_args)\n",
        "        model = Mamba(model_args)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown model name: {model_name}\")\n",
        "\n",
        "    model = model.to(device)\n",
        "    return model\n",
        "\n",
        "def load_test_data(ts_length, data_path):\n",
        "    \"\"\"Load test dataset for evaluation\"\"\"\n",
        "    print(f\"Loading test data from: {data_path}\")\n",
        "    testset_path = Path(data_path)\n",
        "    print(f\"Loading test data from: {testset_path}\")\n",
        "\n",
        "    if not testset_path.exists():\n",
        "        raise FileNotFoundError(f\"Test data file not found: {testset_path}\")\n",
        "\n",
        "    test_data = torch.load(testset_path, weights_only=False)\n",
        "    print(f\"Test data loaded successfully\")\n",
        "    return test_data\n",
        "\n",
        "def setup_environment() -> str:\n",
        "    \"\"\"Set up environment and return device.\"\"\"\n",
        "    import warnings\n",
        "    warnings.filterwarnings('ignore')\n",
        "\n",
        "    # Set random seed for reproducibility\n",
        "    np.random.seed(192390)\n",
        "\n",
        "    # Determine device\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    return device\n",
        "\n",
        "def extract_model_info(file_path: str) -> Optional[Dict[str, Union[str, int, float, Path]]]:\n",
        "    \"\"\"Extract model information from checkpoint file path.\"\"\"\n",
        "    # Updated pattern to handle scientific notation in learning rates (e.g., 1e-05)\n",
        "    pattern = r'(\\w+)_([\\d\\.e\\-]+)_([\\d]+)_64_([\\d]+)_ckpt_([\\d]+)_([\\d]+)\\.pth'\n",
        "\n",
        "    # Convert to Path object if it's a string\n",
        "    path_obj = Path(file_path)\n",
        "\n",
        "    # Check if file exists\n",
        "    if not path_obj.exists():\n",
        "        print(f\"Checkpoint file does not exist: {file_path}\")\n",
        "        return None\n",
        "\n",
        "    match = re.search(pattern, path_obj.name)\n",
        "\n",
        "    if match:\n",
        "        model_info = {\n",
        "            'model': match.group(1),\n",
        "            'learning_rate': float(match.group(2)),\n",
        "            'hidden_size': int(match.group(3)),\n",
        "            'epochs': int(match.group(4)),\n",
        "            'checkpoint_id': int(match.group(5)),\n",
        "            'date': match.group(6),\n",
        "            'matching_file': file_path\n",
        "        }\n",
        "        print(f\"Extracted model info: {model_info['model']}, lr={model_info['learning_rate']}, \"\n",
        "              f\"hidden_size={model_info['hidden_size']}, checkpoint_id={model_info['checkpoint_id']}, \"\n",
        "              f\"date={model_info['date']}\")\n",
        "        return model_info\n",
        "    else:\n",
        "        # Try the old pattern as a fallback\n",
        "        old_pattern = r'(\\w+)_([\\d]+)_64_([\\d]+)_ckpt_([\\d]+)'\n",
        "        match = re.search(old_pattern, path_obj.name)\n",
        "\n",
        "        if match:\n",
        "            model_info = {\n",
        "                'model': match.group(1),\n",
        "                'hidden_size': int(match.group(2)),\n",
        "                'epochs': int(match.group(3)),\n",
        "                'checkpoint_id': int(match.group(4)),\n",
        "                'matching_file': file_path\n",
        "            }\n",
        "            print(f\"Extracted model info (old format): {model_info['model']}, \"\n",
        "                  f\"hidden_size={model_info['hidden_size']}, checkpoint_id={model_info['checkpoint_id']}\")\n",
        "            return model_info\n",
        "        else:\n",
        "            print(f\"Could not extract model info from {file_path} - file name doesn't match expected pattern\")\n",
        "            return None\n",
        "\n",
        "def generate_data(seq_len: int, phase: str) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
        "    \"\"\"Generate data based on sequence length and phase alignment.\"\"\"\n",
        "    print(f\"Generating data with seq_len={seq_len}, phase={phase}\")\n",
        "\n",
        "    # Generate random holdout intervals\n",
        "    np.random.seed(192390)\n",
        "    holdout_intervals = np.random.randint(0, 99, size=10).tolist()\n",
        "    phase_tuple = ast.literal_eval(phase)\n",
        "\n",
        "    try:\n",
        "        if seq_len == 200:\n",
        "            if phase_tuple[0]:\n",
        "                train_inputs, train_targets, test_inputs, test_targets = generate_trace_task(1000, 200, phase_tuple[1], holdout_intervals=holdout_intervals)\n",
        "            else:\n",
        "                train_inputs, train_targets, test_inputs, test_targets = generate_inter_trial_interval(1000, 200, holdout_intervals=holdout_intervals)\n",
        "        elif seq_len == 300:\n",
        "          if phase_tuple[0]:\n",
        "              train_inputs, train_targets, test_inputs, test_targets = generate_trace_task(1000, 300, phase_tuple[1], holdout_intervals=holdout_intervals)\n",
        "          else:\n",
        "              train_inputs, train_targets, test_inputs, test_targets = generate_inter_trial_interval(1000, 300, holdout_intervals=holdout_intervals)\n",
        "        elif seq_len == 400:\n",
        "          if phase_tuple[0]:\n",
        "              train_inputs, train_targets, test_inputs, test_targets = generate_trace_task(1000, 400, phase_tuple[1], holdout_intervals=holdout_intervals)\n",
        "          else:\n",
        "              train_inputs, train_targets, test_inputs, test_targets = generate_inter_trial_interval(1000, 400, holdout_intervals=holdout_intervals)\n",
        "        elif seq_len == 600:\n",
        "            if phase_tuple[0]:\n",
        "                train_inputs, train_targets, test_inputs, test_targets = generate_trace_task(1000, 600, phase_tuple[1], holdout_intervals=holdout_intervals)\n",
        "            else:\n",
        "                train_inputs, train_targets, test_inputs, test_targets = generate_inter_trial_interval(num_seq=1000, n=600, iti=(60, 120), isi=30, holdout_intervals=holdout_intervals)\n",
        "        elif seq_len == 1000:\n",
        "            if phase_tuple[0]:\n",
        "                train_inputs, train_targets, test_inputs, test_targets = generate_trace_task(1000, 1000, phase_tuple[1], holdout_intervals=holdout_intervals)\n",
        "            else:\n",
        "                train_inputs, train_targets, test_inputs, test_targets = generate_inter_trial_interval(num_seq=1000, n=1000, iti=(100, 120), isi=50, holdout_intervals=holdout_intervals)\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported sequence length: {seq_len}\")\n",
        "\n",
        "        # print(f'train inputs {train_inputs.shape} {train_targets.shape}')\n",
        "        # print(f'test inputs {test_inputs.shape} {test_targets.shape}')\n",
        "        return train_inputs, train_targets, test_inputs, test_targets\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating data: {e}\")\n",
        "        raise\n",
        "\n",
        "def evaluate_model(\n",
        "    model_info: Dict[str, Union[str, int, float, Path]],\n",
        "    test_inputs: torch.Tensor,\n",
        "    device: str,\n",
        "    current_seed: str\n",
        ") -> Optional[torch.Tensor]:\n",
        "    \"\"\"Evaluate a model and return its outputs.\"\"\"\n",
        "    model_name = model_info['model']\n",
        "    file_path = model_info['matching_file']\n",
        "    hidden_size = model_info['hidden_size']\n",
        "\n",
        "    print(f\"Evaluating model {model_name} (hidden_size={hidden_size}) from {file_path}\")\n",
        "\n",
        "    try:\n",
        "        # Try to load the checkpoint\n",
        "        try:\n",
        "            checkpoint = torch.load(file_path, map_location=device)\n",
        "            print(f\"Successfully loaded checkpoint\")\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to load checkpoint {file_path}: {e}\")\n",
        "            return None\n",
        "\n",
        "        # Try to initialize the model\n",
        "        try:\n",
        "            model = get_model(model_name, 2, hidden_size, 64, 1).to(device)\n",
        "            print(f\"Successfully initialized model\")\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to initialize model {model_name}: {e}\")\n",
        "            return None\n",
        "\n",
        "        # Try to load the state dict\n",
        "        try:\n",
        "            model.load_state_dict(checkpoint['model_state_dict'])\n",
        "            print(f\"Successfully loaded state dict\")\n",
        "        except KeyError:\n",
        "            print(\"Checkpoint does not contain 'model_state_dict' key\")\n",
        "            if 'state_dict' in checkpoint:\n",
        "                print(\"Trying 'state_dict' key instead\")\n",
        "                try:\n",
        "                    model.load_state_dict(checkpoint['state_dict'])\n",
        "                    print(\"Successfully loaded state dict using 'state_dict' key\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Failed to load alternative state dict: {e}\")\n",
        "                    return None\n",
        "            else:\n",
        "                print(\"No usable state dict found in checkpoint\")\n",
        "                return None\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to load state dict: {e}\")\n",
        "            return None\n",
        "\n",
        "        # print('-----------------')\n",
        "        # if model_name == \"MAMBA\":\n",
        "        #     print(model)\n",
        "        #     for name, param in model.named_parameters():\n",
        "        #         if 'A_log' in name:\n",
        "        #             print(f\"{name}: {param.shape}\")\n",
        "        #             print(param)\n",
        "        # print('-----------------')\n",
        "\n",
        "        # Evaluate the model\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            try:\n",
        "                outputs = torch.softmax(model(test_inputs), dim=-1)[..., 1].cpu().detach().squeeze()\n",
        "                print(f\"Successfully evaluated model, output shape: {outputs.shape}\")\n",
        "                return outputs\n",
        "            except Exception as e:\n",
        "                print(f\"Error during model inference: {e}\")\n",
        "                return None\n",
        "    except Exception as e:\n",
        "        print(f\"Unexpected error evaluating model {model_name}: {e}\")\n",
        "        return None\n",
        "\n",
        "def run_evaluation(\n",
        "    checkpoint_paths: List[str],\n",
        "    seq_len: int = 200,\n",
        "    phase: str = '(True, False)',\n",
        "    sample_idx: int = 3\n",
        ") -> Dict:\n",
        "    \"\"\"\n",
        "    Main evaluation function that can be easily imported and run.\n",
        "\n",
        "    Args:\n",
        "        checkpoint_paths: List of checkpoint file paths. If None, uses defaults.\n",
        "        seq_len: Sequence length for data generation\n",
        "        phase: Phase configuration as string\n",
        "        sample_idx: Sample index (currently unused but kept for compatibility)\n",
        "\n",
        "    Returns:\n",
        "        Dictionary containing all results and data for plotting\n",
        "    \"\"\"\n",
        "\n",
        "    # Determine phase type for logging\n",
        "    if phase == str((True, False)):\n",
        "        type_phase = 'double'\n",
        "    elif phase == str((True, True)):\n",
        "        type_phase = 'conset'\n",
        "    elif phase == str((False, False)):\n",
        "        type_phase = 'offset'\n",
        "    else:\n",
        "        type_phase = 'None'\n",
        "\n",
        "    # Log the configuration\n",
        "    print(f\"Configuration: seq_len={seq_len}, phase={phase}, sample_idx={sample_idx}\")\n",
        "    print(f\"Number of checkpoint paths: {len(checkpoint_paths)}\")\n",
        "\n",
        "    # Setup\n",
        "    device = setup_environment()\n",
        "\n",
        "    # Generate data\n",
        "    train_inputs, train_targets, test_inputs, test_targets = generate_data(seq_len, phase)\n",
        "\n",
        "    # Split data\n",
        "    try:\n",
        "        train_inputs_split, train_targets_split, val_inputs_split, val_targets_split = split_train_val_og(\n",
        "            train_inputs, train_targets, val_split=0.1\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(f\"Error splitting data: {e}\")\n",
        "        return None\n",
        "\n",
        "    # Move test data to device\n",
        "    test_inputs = test_inputs.to(device)\n",
        "    test_targets = test_targets.to(device)\n",
        "\n",
        "    # Create dictionaries to store outputs and model-to-seed mapping\n",
        "    all_outputs_dict = {}\n",
        "    model_to_seed_map = {}\n",
        "\n",
        "    # Process each checkpoint file\n",
        "    for checkpoint_path in checkpoint_paths:\n",
        "        print(f\"Processing checkpoint: {checkpoint_path}\")\n",
        "\n",
        "        # Skip if file doesn't exist\n",
        "        if not Path(checkpoint_path).exists():\n",
        "            print(f\"Checkpoint file does not exist: {checkpoint_path}\")\n",
        "            continue\n",
        "\n",
        "        # Extract model info\n",
        "        model_info = extract_model_info(checkpoint_path) # apple\n",
        "        if model_info is None:\n",
        "            continue\n",
        "\n",
        "        # Extract seed from the checkpoint path\n",
        "        seed_match = re.search(r'_ckpt_(\\d+)_', checkpoint_path)\n",
        "        current_seed = seed_match.group(1) if seed_match else \"unknown\"\n",
        "\n",
        "        # Evaluate model\n",
        "        outputs = evaluate_model(model_info, test_inputs, device, current_seed)\n",
        "\n",
        "        # Create a formatted key for the outputs dictionary that includes learning rate\n",
        "        if 'learning_rate' in model_info:\n",
        "            model_name = f\"{model_info['model']}_{model_info['learning_rate']}_{model_info['checkpoint_id']}\"\n",
        "        else:\n",
        "            model_name = f\"{model_info['model']}_{model_info['checkpoint_id']}\"\n",
        "\n",
        "        if outputs is not None:\n",
        "            all_outputs_dict[model_name] = outputs\n",
        "            model_to_seed_map[model_name] = current_seed\n",
        "\n",
        "    # Process results\n",
        "    if all_outputs_dict:\n",
        "        results_data = []\n",
        "\n",
        "        for k, v in all_outputs_dict.items():\n",
        "            binary_output = (v.to(device) >= 0.5).float()\n",
        "\n",
        "            # Check if at least half of the batch matches at the offset positions\n",
        "            match_ratio, threshold_met, match_details = check_batch_match_at_offset(\n",
        "                binary_output,\n",
        "                test_targets,\n",
        "                match_threshold=0.5  # At least 50% need to match\n",
        "            )\n",
        "\n",
        "            # Get flat batch indices for reference\n",
        "            batch_idx, seq_idx = get_flat_batch_indices(binary_output)\n",
        "\n",
        "            # Print the high-level results\n",
        "            print('='*50)\n",
        "            print(f'Model: {k}')\n",
        "            print(f\"sequence length: {seq_len}\")\n",
        "            print(f\"Match ratio: {match_ratio:.2f}\")\n",
        "            print(f\"Threshold met: {threshold_met}\")\n",
        "            print(f\"Sequences with matches: {match_details['summary']['sequences_with_matches']} out of {match_details['summary']['batch_size']}\")\n",
        "            print(f\"Total matching offsets: {match_details['summary']['total_matches']} out of {match_details['summary']['total_offsets']}\")\n",
        "            print('\\n')\n",
        "\n",
        "            # Store data for plotting\n",
        "            results_data.append({\n",
        "                'model_name': k,\n",
        "                'original_output': v.cpu().detach(),\n",
        "                'binary_output': binary_output.cpu().detach(),\n",
        "                'targets': test_targets.cpu().detach(),\n",
        "                'match_ratio': match_ratio,\n",
        "                'threshold_met': threshold_met,\n",
        "                'match_details': match_details\n",
        "            })\n",
        "\n",
        "        return {\n",
        "            'results_data': results_data,\n",
        "            'all_outputs_dict': all_outputs_dict,\n",
        "            'seq_len': seq_len,\n",
        "            'type_phase': type_phase,\n",
        "            'test_targets': test_targets.cpu().detach(),\n",
        "            'model_to_seed_map': model_to_seed_map,\n",
        "            'train_data': {\n",
        "                'train_inputs': train_inputs,\n",
        "                'train_targets': train_targets,\n",
        "                'train_inputs_split': train_inputs_split,\n",
        "                'train_targets_split': train_targets_split,\n",
        "                'val_inputs_split': val_inputs_split,\n",
        "                'val_targets_split': val_targets_split\n",
        "            }\n",
        "        }\n",
        "    else:\n",
        "        print(\"No models were successfully evaluated.\")\n",
        "        return None\n",
        "\n",
        "# Convenience functions for common use cases\n",
        "def evaluate_single_model(checkpoint_path: str, seq_len: int = 200, phase: str = '(True, False)'):\n",
        "    \"\"\"Evaluate a single model.\"\"\"\n",
        "    return run_evaluation([checkpoint_path], seq_len, phase)\n",
        "\n",
        "def evaluate_default_models(seq_len: int = 200, phase: str = '(True, False)'):\n",
        "    \"\"\"Evaluate the default MAMBA and S4D models.\"\"\"\n",
        "    return run_evaluation(None, seq_len, phase)\n",
        "\n",
        "def evaluate_custom_models(checkpoint_paths: List[str], seq_len: int = 200, phase: str = '(True, False)'):\n",
        "    \"\"\"Evaluate custom list of models.\"\"\"\n",
        "    return run_evaluation(checkpoint_paths, seq_len, phase)\n",
        "\n",
        "# For backward compatibility\n",
        "def main(checkpoint_path, seq_len, phase, sample_idx):\n",
        "    \"\"\"Legacy main function - redirects to run_evaluation.\"\"\"\n",
        "    return run_evaluation([checkpoint_path], seq_len, phase, sample_idx)"
      ],
      "metadata": {
        "id": "J3-RHyXyFUid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# trainer.py\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm.auto import tqdm\n",
        "import numpy as np\n",
        "import os\n",
        "from pathlib import Path\n",
        "import datetime\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "print(os.getcwd())\n",
        "\n",
        "\n",
        "def trainer(model_name, hidden_s, state_size, memory_size, epochs_length, seed, ckpt_dir, ts_length, lr, clip_grad=None):\n",
        "\n",
        "    trainset_path = Path(f'datasets/train_{ts_length}_colab.pth')\n",
        "    testset_path = Path(f'datasets/test_{ts_length}_colab.pth')\n",
        "    valset_path = Path(f'datasets/val_{ts_length}_colab.pth')\n",
        "    datasets = [trainset_path, testset_path, valset_path]\n",
        "    pbar = tqdm(enumerate(datasets))\n",
        "\n",
        "\n",
        "    # params\n",
        "    batch_size = 128\n",
        "    num_workers = 2\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "    epochs = epochs_length\n",
        "\n",
        "    hidden_size = hidden_s\n",
        "    state_size = state_size\n",
        "\n",
        "    d_output = 1\n",
        "    vocab_size = 2\n",
        "    output_size = 1\n",
        "    num_layers = 1\n",
        "    batch_first = True\n",
        "    dropout = 0\n",
        "    prenorm = False\n",
        "\n",
        "    for _, dataset in pbar:\n",
        "        np.random.seed(seed)\n",
        "        print(f'\\nMaking a new set of Train, Test and Validation data.')\n",
        "        hld_ot_int = np.random.randint(0, 99, size=200).tolist()\n",
        "\n",
        "        if ts_length == 200:\n",
        "            train_inputs, train_targets, test_inputs, test_targets = generate_inter_trial_interval(num_seq=1000, n=200, iti=(20, 40), isi=10, holdout_intervals=hld_ot_int)\n",
        "        if ts_length == 600:\n",
        "            train_inputs, train_targets, test_inputs, test_targets = generate_inter_trial_interval(num_seq=1000, n=600, iti=(60, 120), isi=30 ,holdout_intervals=hld_ot_int)\n",
        "        if ts_length == 1000:\n",
        "            train_inputs, train_targets, test_inputs, test_targets = generate_inter_trial_interval(num_seq=1000, n=1000, iti=(100, 200), isi=50 ,holdout_intervals=hld_ot_int)\n",
        "\n",
        "        train_inputs_split, train_targets_split, val_inputs_split, val_targets_split = split_train_val_og(train_inputs, train_targets, val_split=0.1)\n",
        "\n",
        "        # Save tensors to a file\n",
        "        torch.save({'inputs': test_inputs, 'targets': test_targets}, Path(f'datasets/test_{ts_length}.pth'))\n",
        "\n",
        "        train_set = AlternatingSignalDataset(train_inputs_split, train_targets_split)\n",
        "        val_set = AlternatingSignalDataset(val_inputs_split, val_targets_split)\n",
        "        test_set = AlternatingSignalDataset(test_inputs, test_targets)\n",
        "        # load datasets\n",
        "        trainset, _ = split_train_val(train_set, val_split=0.2)\n",
        "        _, valset = split_train_val(val_set, val_split=0.1)\n",
        "        testset, _ = split_train_val(test_set, val_split=0)\n",
        "\n",
        "        torch.save(trainset, trainset_path)\n",
        "        torch.save(valset, valset_path)\n",
        "        torch.save(testset, testset_path)\n",
        "\n",
        "        print('\\nDatasets created!')\n",
        "\n",
        "        # Dataloaders\n",
        "        trainloader = DataLoader(\n",
        "            trainset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "        valloader = DataLoader(\n",
        "            valset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "        testloader = DataLoader(\n",
        "            testset, batch_size=2, shuffle=False, num_workers=num_workers)\n",
        "        pbar.set_description('Datasets loaded (%d/%d)' % (3,3))\n",
        "\n",
        "    # save the model params into a file\n",
        "    with open(f'model_params_experiments_{ts_length}.json', '+a') as file:\n",
        "        mode_info = {\n",
        "            'model_name' : model_name +f'_experiments_{ts_length}' ,\n",
        "            'seed' : seed,\n",
        "            'hidden_size' : hidden_size,\n",
        "            'learning_rate' : lr,\n",
        "            'state/memory_size' : state_size,\n",
        "            'num_layers' : num_layers,\n",
        "            'dropout' : dropout,\n",
        "            'prenorm' : prenorm,\n",
        "            'batch_size' : batch_size,\n",
        "            'training_timestamp' : str(datetime.datetime.now()),\n",
        "            'epochs' : epochs,\n",
        "            'ts_shape' : trainset.dataset.inputs.shape\n",
        "        }\n",
        "\n",
        "        json.dump(mode_info, file, indent=4)\n",
        "\n",
        "    model = get_model(model_name, vocab_size, hidden_size, state_size, num_layers)\n",
        "\n",
        "\n",
        "    if model_name == 'S4D':\n",
        "        criterion = torch.nn.CrossEntropyLoss()\n",
        "        optimizer, _ = setup_optimizer(model, lr=lr, weight_decay=0.01, epochs=epochs)\n",
        "\n",
        "    else:\n",
        "        criterion = torch.nn.CrossEntropyLoss()\n",
        "        optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
        "\n",
        "\n",
        "    model = model.to(device)\n",
        "    if device == 'cuda':\n",
        "        cudnn.benchmark = True\n",
        "\n",
        "    all_mse_list = []\n",
        "    all_loss_list = []\n",
        "\n",
        "    print(f'\\ntraining {model_name}-{seed}')\n",
        "    pbar = tqdm(range(epochs), desc='Epoch 0')\n",
        "\n",
        "    for epoch in pbar:\n",
        "        current_date = datetime.date.today().strftime('%Y%m%d')\n",
        "\n",
        "        average_loss, accuracy = train(\n",
        "            model=model,\n",
        "            dataloader=trainloader,\n",
        "            device=device,\n",
        "            optimizer=optimizer,\n",
        "            criterion=criterion,\n",
        "            model_name=model_name,\n",
        "            grad_clip=clip_grad,\n",
        "            mse_log=all_mse_list,\n",
        "            loss_log=all_loss_list\n",
        "        )\n",
        "\n",
        "        # Update tqdm with epoch and loss\n",
        "        pbar.set_description(f\"Epoch {epoch}\")\n",
        "        pbar.set_postfix(loss=f\"{average_loss:.4f}\")\n",
        "\n",
        "        # Save checkpoint\n",
        "        ckpt_path = f'./{ckpt_dir}/{model_name}/'\n",
        "        os.makedirs(ckpt_path, exist_ok=True)\n",
        "        checkpoint_path = f'{ckpt_path}{model_name}_{lr}_{hidden_size}_{state_size}_{epochs}_ckpt_{seed}_{current_date}.pth'\n",
        "\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "        }, checkpoint_path)\n",
        "\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "    axs[0].plot(all_mse_list, marker='o')\n",
        "    axs[0].set_title(\"MSE over All Batches\")\n",
        "    axs[0].set_xlabel(\"Batch Index\")\n",
        "    axs[0].set_ylabel(\"MSE\")\n",
        "    axs[0].grid(True)\n",
        "\n",
        "    axs[1].plot(all_loss_list, marker='x', color='orange')\n",
        "    axs[1].set_title(\"Loss over All Batches\")\n",
        "    axs[1].set_xlabel(\"Batch Index\")\n",
        "    axs[1].set_ylabel(\"Loss\")\n",
        "    axs[1].grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(f'\\nfinished training {model_name}-{seed}')"
      ],
      "metadata": {
        "id": "ZXVFIFSKFBYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plotters.py\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "from typing import Optional, Union\n",
        "import os\n",
        "\n",
        "def plot_signals_with_offsets(\n",
        "    original_output: torch.Tensor,\n",
        "    binary_output: torch.Tensor,\n",
        "    targets: torch.Tensor,\n",
        "    model_name: str,\n",
        "    num_samples: int = 4,\n",
        "    ts_length: int = 200,\n",
        "    type_phase: str = 'unknown'\n",
        ") -> plt.Figure:\n",
        "    \"\"\"\n",
        "    Plot original outputs, binary outputs, and targets with offset markers.\n",
        "\n",
        "    Args:\n",
        "        original_output: Raw model outputs (continuous values)\n",
        "        binary_output: Thresholded binary outputs\n",
        "        targets: Target values\n",
        "        model_name: Name of the model for the title\n",
        "        num_samples: Number of samples to plot\n",
        "        ts_length: Length of time series\n",
        "        type_phase: Type of phase for labeling\n",
        "\n",
        "    Returns:\n",
        "        matplotlib Figure object\n",
        "    \"\"\"\n",
        "    # Ensure tensors are on CPU for plotting\n",
        "    if isinstance(original_output, torch.Tensor):\n",
        "        original_output = original_output.cpu().detach()\n",
        "    if isinstance(binary_output, torch.Tensor):\n",
        "        binary_output = binary_output.cpu().detach()\n",
        "    if isinstance(targets, torch.Tensor):\n",
        "        targets = targets.cpu().detach()\n",
        "\n",
        "    # Limit number of samples to what's available\n",
        "    num_samples = min(num_samples, original_output.shape[0])\n",
        "    plt.style.use('fivethirtyeight')\n",
        "    plt.rcParams['axes.facecolor'] = 'white'\n",
        "    plt.rcParams['figure.facecolor'] = 'white'\n",
        "    # Create figure with subplots\n",
        "    fig, axes = plt.subplots(num_samples, 1, figsize=(15, 3 * num_samples))\n",
        "    if num_samples == 1:\n",
        "        axes = [axes]\n",
        "\n",
        "    # Color scheme\n",
        "    colors = {\n",
        "        'original': 'blue',\n",
        "        'binary': 'red',\n",
        "        'target': 'green',\n",
        "        'offset_marker': 'orange'\n",
        "    }\n",
        "\n",
        "    for i in range(num_samples):\n",
        "        ax = axes[i]\n",
        "\n",
        "        # Plot original output (continuous)\n",
        "        ax.plot(original_output[i],\n",
        "               color=colors['original'],\n",
        "               alpha=0.7,\n",
        "               linewidth=2,\n",
        "               label='Original Output')\n",
        "\n",
        "        # Plot binary output\n",
        "        ax.plot(binary_output[i],\n",
        "               color=colors['binary'],\n",
        "               alpha=0.8,\n",
        "               linewidth=1.5,\n",
        "               label='Binary Output',\n",
        "               linestyle='--')\n",
        "\n",
        "        # Plot targets\n",
        "        ax.plot(targets[i],\n",
        "               color=colors['target'],\n",
        "               alpha=0.6,\n",
        "               linewidth=2,\n",
        "               label='Target',\n",
        "               linestyle=':')\n",
        "\n",
        "        # Add offset markers (vertical lines where targets change from 0 to 1)\n",
        "        try:\n",
        "            target_diff = torch.diff(targets[i].float(), prepend=torch.tensor([0.0]))\n",
        "            onset_indices = torch.where(target_diff > 0.5)[0]\n",
        "\n",
        "            for onset_idx in onset_indices:\n",
        "                ax.axvline(x=onset_idx.item(),\n",
        "                          color=colors['offset_marker'],\n",
        "                          linestyle=':',\n",
        "                          alpha=0.8,\n",
        "                          linewidth=2)\n",
        "\n",
        "            if len(onset_indices) > 0 and i == 0:  # Add legend entry only once\n",
        "                ax.axvline(x=-1, color=colors['offset_marker'],\n",
        "                          linestyle=':', label='Target Onsets', linewidth=2)\n",
        "        except Exception as e:\n",
        "            # print(f\"Warning: Could not add offset markers for sample {i}: {e}\")\n",
        "            pass\n",
        "\n",
        "        # Formatting\n",
        "        ax.set_xlim(0, ts_length)\n",
        "        ax.set_ylim(-0.1, 1.1)\n",
        "        ax.set_ylabel('Signal Value')\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        ax.set_title(f'Sample {i+1} - {model_name} ({type_phase})')\n",
        "\n",
        "        # Add legend only to first subplot to avoid clutter\n",
        "        if i == 0:\n",
        "            ax.legend(loc='upper right', fontsize=10)\n",
        "\n",
        "    # Set xlabel only for bottom subplot\n",
        "    axes[-1].set_xlabel('Time Steps')\n",
        "\n",
        "    # Overall title\n",
        "    fig.suptitle(f'{model_name} - Signal Analysis ({type_phase})',\n",
        "                fontsize=16, fontweight='bold')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    return fig\n",
        "\n",
        "def setup_colors() -> dict:\n",
        "    \"\"\"Set up colors for different models.\"\"\"\n",
        "    return {\n",
        "        'LSTM': plt.get_cmap(\"tab10\")(0),  # Blue\n",
        "        'GRU': plt.get_cmap(\"tab10\")(1),   # Orange\n",
        "        'RNN': plt.get_cmap(\"tab10\")(2),   # Green\n",
        "        'Transformer': plt.get_cmap(\"tab10\")(3),  # Red\n",
        "        'S4D': plt.get_cmap(\"tab10\")(4),   # Purple\n",
        "        'MAMBA': plt.get_cmap(\"tab10\")(5),  # Brown\n",
        "        'NRU': plt.get_cmap(\"tab10\")(6),   # Pink\n",
        "    }\n",
        "\n",
        "def plot_comparison_summary(\n",
        "    all_outputs_dict: dict,\n",
        "    targets: torch.Tensor,\n",
        "    seq_len: int,\n",
        "    type_phase: str,\n",
        "    sample_idx: int = 0\n",
        ") -> plt.Figure:\n",
        "    \"\"\"\n",
        "    Create a summary comparison plot of all models for a single sample.\n",
        "\n",
        "    Args:\n",
        "        all_outputs_dict: Dictionary of model outputs\n",
        "        targets: Target tensor\n",
        "        seq_len: Sequence length\n",
        "        type_phase: Phase type\n",
        "        sample_idx: Which sample to plot\n",
        "\n",
        "    Returns:\n",
        "        matplotlib Figure object\n",
        "    \"\"\"\n",
        "    colors = setup_colors()\n",
        "    plt.style.use('fivethirtyeight')\n",
        "    plt.rcParams['axes.facecolor'] = 'white'\n",
        "    plt.rcParams['figure.facecolor'] = 'white'\n",
        "    fig, ax = plt.subplots(1, 1, figsize=(15, 8))\n",
        "\n",
        "    # Plot targets first\n",
        "    if isinstance(targets, torch.Tensor):\n",
        "        targets = targets.cpu().detach()\n",
        "\n",
        "    ax.plot(targets[sample_idx],\n",
        "           color='black',\n",
        "           linewidth=3,\n",
        "           label='Target',\n",
        "           alpha=0.8)\n",
        "\n",
        "    # Plot each model's output\n",
        "    for i, (model_name, outputs) in enumerate(all_outputs_dict.items()):\n",
        "        if isinstance(outputs, torch.Tensor):\n",
        "            outputs = outputs.cpu().detach()\n",
        "\n",
        "        # Get model type for coloring\n",
        "        model_type = model_name.split('_')[0]\n",
        "        color = colors.get(model_type, plt.get_cmap(\"tab10\")(i % 10))\n",
        "\n",
        "        # Plot binary output\n",
        "        binary_output = (outputs >= 0.5).float()\n",
        "        ax.plot(binary_output[sample_idx],\n",
        "               color=color,\n",
        "               linewidth=2,\n",
        "               label=f'{model_name} (Binary)',\n",
        "               alpha=0.7,\n",
        "               linestyle='--')\n",
        "\n",
        "        # Plot original output with transparency\n",
        "        ax.plot(outputs[sample_idx],\n",
        "               color=color,\n",
        "               linewidth=1,\n",
        "               alpha=0.4,\n",
        "               linestyle='-')\n",
        "\n",
        "    # Add onset markers\n",
        "    try:\n",
        "        target_diff = torch.diff(targets[sample_idx].float(), prepend=torch.tensor([0.0]))\n",
        "        onset_indices = torch.where(target_diff > 0.5)[0]\n",
        "\n",
        "        for onset_idx in onset_indices:\n",
        "            ax.axvline(x=onset_idx.item(),\n",
        "                      color='red',\n",
        "                      linestyle=':',\n",
        "                      alpha=0.6,\n",
        "                      linewidth=1)\n",
        "    except Exception as e:\n",
        "        # print(f\"Warning: Could not add onset markers: {e}\")\n",
        "        pass\n",
        "\n",
        "    ax.set_xlim(0, seq_len)\n",
        "    ax.set_ylim(-0.1, 1.1)\n",
        "    ax.set_xlabel('Time Steps')\n",
        "    ax.set_ylabel('Signal Value')\n",
        "    ax.set_title(f'Model Comparison - Sample {sample_idx + 1} ({type_phase})')\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    return fig\n",
        "\n",
        "def plot_results(results_dict, save_plots=True, output_dir='./model_outputs/'):\n",
        "    \"\"\"\n",
        "    Generate all plots from results dictionary returned by main().\n",
        "\n",
        "    Args:\n",
        "        results_dict: Dictionary returned by main() function\n",
        "        save_plots: Whether to save plots to disk\n",
        "        output_dir: Directory to save plots\n",
        "    \"\"\"\n",
        "    results_data = results_dict['results_data']\n",
        "    seq_len = results_dict['seq_len']\n",
        "    type_phase = results_dict['type_phase']\n",
        "    all_outputs_dict = results_dict['all_outputs_dict']\n",
        "    test_targets = results_dict['test_targets']\n",
        "\n",
        "    all_figures = []\n",
        "\n",
        "    # Individual model plots\n",
        "    for result in results_data:\n",
        "        fig = plot_signals_with_offsets(\n",
        "            original_output=result['original_output'],\n",
        "            binary_output=result['binary_output'],\n",
        "            targets=result['targets'],\n",
        "            model_name=result['model_name'],\n",
        "            num_samples=min(4, result['original_output'].shape[0]),\n",
        "            ts_length=seq_len,\n",
        "            type_phase=type_phase\n",
        "        )\n",
        "\n",
        "        if save_plots:\n",
        "            save_dir = f\"./finalize/{output_dir}/{type_phase}/\"\n",
        "            os.makedirs(save_dir, exist_ok=True)\n",
        "            fig.savefig(f\"{save_dir}{result['model_name']}_{type_phase}_signals_plot.png\",\n",
        "                       bbox_inches='tight', dpi=300)\n",
        "            print(f\"Saved plot for {result['model_name']}\")\n",
        "\n",
        "        all_figures.append(fig)\n",
        "        plt.show()\n",
        "\n",
        "    # Comparison plot\n",
        "    if len(all_outputs_dict) > 1:\n",
        "        comparison_fig = plot_comparison_summary(\n",
        "            all_outputs_dict=all_outputs_dict,\n",
        "            targets=test_targets,\n",
        "            seq_len=seq_len,\n",
        "            type_phase=type_phase,\n",
        "            sample_idx=0\n",
        "        )\n",
        "\n",
        "        if save_plots:\n",
        "            save_dir = f\"./finalize/{output_dir}/{type_phase}/\"\n",
        "            os.makedirs(save_dir, exist_ok=True)\n",
        "            comparison_fig.savefig(f\"{save_dir}comparison_{type_phase}_plot.png\",\n",
        "                                 bbox_inches='tight', dpi=300)\n",
        "            print(\"Saved comparison plot\")\n",
        "\n",
        "        all_figures.append(comparison_fig)\n",
        "        plt.show()\n",
        "\n",
        "    return all_figures\n",
        "\n",
        "\n",
        "def plot_joint_outputs_from_two_runs(\n",
        "    results1,\n",
        "    results2,\n",
        "    model_names = (\"MAMBA\", \"S4D\"),\n",
        "    sample_idx = 3\n",
        "):\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    for res1, res2 in zip(results1, results2):\n",
        "        phase1 = res1.get(\"type_phase\", \"unknown\")\n",
        "        phase2 = res2.get(\"type_phase\", \"unknown\")\n",
        "\n",
        "        # make sure they are aligned by type_phase\n",
        "        if phase1 != phase2:\n",
        "            print(f\"Skipping: mismatched phases ({phase1} vs {phase2})\")\n",
        "            continue\n",
        "\n",
        "        target = res1[\"test_targets\"][sample_idx].cpu().detach().numpy()\n",
        "\n",
        "        plt.figure(figsize=(12, 4))\n",
        "\n",
        "        # Plot model 1 (MAMBA)\n",
        "        for name, out in res1[\"all_outputs_dict\"].items():\n",
        "            if model_names[0] in name:\n",
        "                plt.plot(out[sample_idx].cpu().detach().numpy(), label=model_names[0], linewidth=2)\n",
        "\n",
        "        # Plot model 2 (S4D)\n",
        "        for name, out in res2[\"all_outputs_dict\"].items():\n",
        "            if model_names[1] in name:\n",
        "                plt.plot(out[sample_idx].cpu().detach().numpy(), label=model_names[1], linewidth=2)\n",
        "\n",
        "        # Plot target last so it's on top\n",
        "        plt.plot(target, 'g--', label=\"Target\", linewidth=2)\n",
        "\n",
        "        print(res1.keys())\n",
        "\n",
        "        plt.title(f\"{model_names[0]} vs {model_names[1]} ({phase1})\")\n",
        "        plt.xlabel(\"Time Step\")\n",
        "        plt.ylabel(\"Value\")\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        plt.savefig(f\"{model_names[0]}-vs-{model_names[1]}-({phase1}).pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "-VnMRnezYrJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train models"
      ],
      "metadata": {
        "id": "pVPXhoErVUFZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "hld_ot_int = np.random.randint(0, 99, size=200).tolist()\n",
        "train_inputs, train_targets, test_inputs, test_targets = generate_inter_trial_interval(num_seq=1000, n=200, iti=(20, 40), isi=10, holdout_intervals=hld_ot_int)\n",
        "train_inputs_split, train_targets_split, val_inputs_split, val_targets_split = split_train_val_og(train_inputs, train_targets, val_split=0.1)\n",
        "\n",
        "train_set = AlternatingSignalDataset(train_inputs_split, train_targets_split)\n",
        "val_set = AlternatingSignalDataset(val_inputs_split, val_targets_split)\n",
        "test_set = AlternatingSignalDataset(test_inputs, test_targets)\n",
        "# load datasets\n",
        "trainset, _ = split_train_val(train_set, val_split=0.2)\n",
        "_, valset = split_train_val(val_set, val_split=0.1)\n",
        "testset, _ = split_train_val(test_set, val_split=0)\n",
        "\n",
        "test_loader = DataLoader(testset, batch_size=64, shuffle=False)\n",
        "print(test_loader)"
      ],
      "metadata": {
        "id": "JJvybXtOVoYt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train Mamba model"
      ],
      "metadata": {
        "id": "O-awAJ1J2eG7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir datasets"
      ],
      "metadata": {
        "id": "vRaV3Dp6GzfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "trainer(\n",
        "    model_name='MAMBA',\n",
        "    hidden_s=8,\n",
        "    state_size=64,\n",
        "    memory_size=64,\n",
        "    epochs_length=60,\n",
        "    seed=123,\n",
        "    ckpt_dir='./mamba_ckpts/',\n",
        "    ts_length=200,\n",
        "    lr=0.01\n",
        ")"
      ],
      "metadata": {
        "id": "dDsYnx7EXNx7",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot the results for offset prediction with the trained model. Also, plot the results for the two generalization experiments: two ISIs and Double-ISI."
      ],
      "metadata": {
        "id": "KqX57TOz1dvJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define your checkpoint base directory\n",
        "ckpt_base = Path(\"./mamba_ckpts\")\n",
        "\n",
        "# Collect all .pth checkpoints recursively\n",
        "checkpoint_paths = sorted([str(p) for p in ckpt_base.glob(\"**/*.pth\")])\n",
        "print(f\"Found {len(checkpoint_paths)} checkpoint files\")\n",
        "\n",
        "# Define your experiments\n",
        "phases = {\n",
        "    \"offset\": '(False, False)',\n",
        "    \"consec\": '(True, True)',\n",
        "    \"double\": '(True, False)',\n",
        "}\n",
        "\n",
        "# Run evaluation for each phase\n",
        "results = []\n",
        "for name, phase in phases.items():\n",
        "    print(f\"\\nRunning evaluation for: {name} phase\")\n",
        "    result = evaluate_custom_models(checkpoint_paths, seq_len=200, phase=phase)\n",
        "    results.append(result)\n",
        "\n",
        "# Plot results\n",
        "for result in results:\n",
        "    if result:\n",
        "        print(f\"Processing experiment: {result['type_phase']}\")\n",
        "        print(\"Generating plots...\")\n",
        "        figures = plot_results(result, save_plots=True)\n",
        "        print(\"All done!\")\n",
        "    else:\n",
        "        print(\"No results to plot - check your model paths and dependencies!\")\n"
      ],
      "metadata": {
        "id": "SgUXNHPYswBE",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train S4D model"
      ],
      "metadata": {
        "id": "Uk6a8trH2k9t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "trainer(\n",
        "    model_name='S4D',\n",
        "    hidden_s=8,\n",
        "    state_size=64,\n",
        "    memory_size=64,\n",
        "    epochs_length=80,\n",
        "    seed=879965,\n",
        "    ckpt_dir='./s4d_ckpts/',\n",
        "    ts_length=200,\n",
        "    lr=0.001\n",
        ")"
      ],
      "metadata": {
        "id": "tUlWcaoXsyt4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot the results for offset prediction with the trained model. Also, plot the results for the two generalization experiments: two ISIs and Double-ISI."
      ],
      "metadata": {
        "id": "wO20LSGW1zCG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define your checkpoint base directory\n",
        "ckpt_base = Path(\"./s4d_ckpts\")\n",
        "\n",
        "# Collect all .pth checkpoints recursively\n",
        "checkpoint_paths = sorted([str(p) for p in ckpt_base.glob(\"**/*.pth\")])\n",
        "print(f\"Found {len(checkpoint_paths)} checkpoint files\")\n",
        "\n",
        "# Define your experiments\n",
        "phases = {\n",
        "    \"offset\": '(False, False)',\n",
        "    \"consec\": '(True, True)',\n",
        "    \"double\": '(True, False)',\n",
        "}\n",
        "\n",
        "# Run evaluation for each phase\n",
        "results = []\n",
        "for name, phase in phases.items():\n",
        "    print(f\"\\nRunning evaluation for: {name} phase\")\n",
        "    result = evaluate_custom_models(checkpoint_paths, seq_len=200, phase=phase)\n",
        "    results.append(result)\n",
        "\n",
        "# Plot results\n",
        "for result in results:\n",
        "    if result:\n",
        "        print(f\"Processing experiment: {result['type_phase']}\")\n",
        "        print(\"Generating plots...\")\n",
        "        figures = plot_results(result, save_plots=True)\n",
        "        print(\"All done!\")\n",
        "    else:\n",
        "        print(\"No results to plot - check your model paths and dependencies!\")\n",
        "2"
      ],
      "metadata": {
        "id": "nromXPnUas6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Plot results for both models\n"
      ],
      "metadata": {
        "id": "88A-MIg09co8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# Define checkpoint directories\n",
        "mamba_ckpt_base = Path(\"./mamba_ckpts\")\n",
        "s4d_ckpt_base = Path(\"./s4d_ckpts\")\n",
        "\n",
        "# Collect all .pth checkpoints recursively\n",
        "mamba_ckpts = sorted([str(p) for p in mamba_ckpt_base.glob(\"**/*.pth\")])\n",
        "s4d_ckpts = sorted([str(p) for p in s4d_ckpt_base.glob(\"**/*.pth\")])\n",
        "print(f\"Found {len(mamba_ckpts)} MAMBA and {len(s4d_ckpts)} S4D checkpoint files\")\n",
        "\n",
        "# Define your experiments\n",
        "phases = {\n",
        "    \"offset\": '(False, False)',\n",
        "    \"consec\": '(True, True)',\n",
        "    \"double\": '(True, False)',\n",
        "}\n",
        "\n",
        "# Run evaluation for each phase\n",
        "mamba_results = []\n",
        "s4d_results = []\n",
        "\n",
        "for name, phase in phases.items():\n",
        "    print(f\"\\nEvaluating phase: {name}\")\n",
        "\n",
        "    print(\"Running MAMBA...\")\n",
        "    mamba_result = evaluate_custom_models(mamba_ckpts, seq_len=200, phase=phase)\n",
        "    mamba_results.append(mamba_result)\n",
        "\n",
        "    print(\"Running S4D...\")\n",
        "    s4d_result = evaluate_custom_models(s4d_ckpts, seq_len=200, phase=phase)\n",
        "    s4d_results.append(s4d_result)\n",
        "\n",
        "# Plot MAMBA vs S4D outputs together\n",
        "print(\"\\nPlotting MAMBA vs S4D outputs...\")\n",
        "plot_joint_outputs_from_two_runs(mamba_results, s4d_results, model_names=(\"MAMBA\", \"S4D\"), sample_idx=3)\n"
      ],
      "metadata": {
        "id": "KmO9oIvNwY1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extensive experiments: Training models on signal length 200 for 80 epochs each, and testing on lengths 200, 300, 400."
      ],
      "metadata": {
        "id": "wXfdtyFl0oJu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "# CONFIG\n",
        "models = ['S4D', 'MAMBA']\n",
        "ckpt_dirs = {\n",
        "    'MAMBA': Path(\"./mamba_ckpts\"),\n",
        "    'S4D': Path(\"./s4d_ckpts\"),\n",
        "}\n",
        "epoch_lengths = [80]\n",
        "seq_lengths = [200, 300, 400]  # 1x, 1.5x, 2x\n",
        "phases = {\n",
        "    \"offset\": '(False, False)',\n",
        "    \"consec\": '(True, True)',\n",
        "    \"double\": '(True, False)',\n",
        "}\n",
        "\n",
        "# STORAGE\n",
        "all_results = []\n",
        "\n",
        "# TRAIN + EVALUATE\n",
        "for epochs in epoch_lengths:\n",
        "    for model in models:\n",
        "        if model == 'S4D': lr = 0.005\n",
        "        else: lr = 0.01\n",
        "        ckpt_dir = ckpt_dirs[model]\n",
        "\n",
        "        # 1. TRAIN\n",
        "        display(Markdown(f\"# Training `{model}` for {epochs} epochs\"))\n",
        "        trainer(\n",
        "            model_name=model,\n",
        "            hidden_s=8,\n",
        "            state_size=64,\n",
        "            memory_size=64,\n",
        "            epochs_length=epochs,\n",
        "            seed=87996,\n",
        "            ckpt_dir=str(ckpt_dir),\n",
        "            ts_length=200,\n",
        "            lr=lr\n",
        "        )\n",
        "\n",
        "        # 2. COLLECT CHECKPOINTS\n",
        "        checkpoint_paths = sorted([str(p) for p in ckpt_dir.glob(\"**/*.pth\")])\n",
        "        display(Markdown(f\"**Found {len(checkpoint_paths)} checkpoint(s) in `{ckpt_dir}`**\"))\n",
        "\n",
        "        # 3. EVALUATE\n",
        "        for seq_len in seq_lengths:\n",
        "            display(Markdown(f\"## Evaluating `{model}` at sequence length {seq_len}\"))\n",
        "            for phase_name, phase in phases.items():\n",
        "                display(Markdown(f\"**Phase: {phase_name}**\"))\n",
        "                result = evaluate_custom_models(checkpoint_paths, seq_len=seq_len, phase=phase)\n",
        "                if result:\n",
        "                    result['meta'] = {\n",
        "                        'model': model,\n",
        "                        'epochs': epochs,\n",
        "                        'seq_len': seq_len,\n",
        "                        'phase': phase_name,\n",
        "                        'ckpts': checkpoint_paths,\n",
        "                    }\n",
        "                    all_results.append(result)\n",
        "                else:\n",
        "                    print(f\"[WARNING] No result for {model} | phase={phase_name} | seq_len={seq_len} | epochs={epochs}\")\n",
        "\n",
        "# 4. FINAL PLOTS\n",
        "display(Markdown(\"# Final Plots for All Experiments\"))\n",
        "\n",
        "for result in all_results:\n",
        "    meta = result['meta']\n",
        "    title = f\"{meta['model']} | {meta['phase']} | {meta['seq_len']} steps | {meta['epochs']} epochs\"\n",
        "    display(Markdown(f\"### {title}\"))\n",
        "    figures = plot_results(result, save_plots=True)\n",
        "    for fig in figures:\n",
        "        plt.figure(fig.number)\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "Ld5zpjnyfgwm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "# Setup\n",
        "phases = {\n",
        "    \"offset\": '(False, False)',\n",
        "    \"consec\": '(True, True)',\n",
        "    \"double\": '(True, False)',\n",
        "}\n",
        "seq_lengths = [200, 300, 400]  # adjust as needed\n",
        "\n",
        "# Define checkpoint directories\n",
        "mamba_ckpt_base = Path(\"./mamba_ckpts\")\n",
        "s4d_ckpt_base = Path(\"./s4d_ckpts\")\n",
        "\n",
        "# Collect checkpoints\n",
        "mamba_ckpts = sorted([str(p) for p in mamba_ckpt_base.glob(\"**/*.pth\")])\n",
        "s4d_ckpts = sorted([str(p) for p in s4d_ckpt_base.glob(\"**/*.pth\")])\n",
        "print(f\"Found {len(mamba_ckpts)} MAMBA and {len(s4d_ckpts)} S4D checkpoint files\")\n",
        "\n",
        "# Run comparison\n",
        "for seq_len in seq_lengths:\n",
        "    for phase_name, phase in phases.items():\n",
        "        display(Markdown(f\"## Comparing MAMBA vs S4D | Phase: `{phase_name}` | Sequence Length: {seq_len}\"))\n",
        "\n",
        "        try:\n",
        "            mamba_result = evaluate_custom_models(mamba_ckpts, seq_len=seq_len, phase=phase)\n",
        "            s4d_result = evaluate_custom_models(s4d_ckpts, seq_len=seq_len, phase=phase)\n",
        "\n",
        "            # Check both are dicts (i.e., valid result objects)\n",
        "            if isinstance(mamba_result, dict) and isinstance(s4d_result, dict):\n",
        "                plot_joint_outputs_from_two_runs(\n",
        "                    mamba_result, s4d_result,\n",
        "                    model_names=(\"MAMBA\", \"S4D\"),\n",
        "                    sample_idx=3\n",
        "                )\n",
        "            else:\n",
        "                print(f\"[SKIPPED] One of the results is invalid for phase={phase_name}, seq_len={seq_len}\")\n",
        "                if not isinstance(mamba_result, dict):\n",
        "                    print(\"  [MAMBA] Invalid result:\", type(mamba_result), mamba_result)\n",
        "                if not isinstance(s4d_result, dict):\n",
        "                    print(\"  [S4D] Invalid result:\", type(s4d_result), s4d_result)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"[ERROR] Exception for phase={phase_name}, seq_len={seq_len}: {e}\")\n"
      ],
      "metadata": {
        "id": "CcYL0n1ub7Ik"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}